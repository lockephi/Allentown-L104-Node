// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// B03_SIMDAccelerate.swift
// [EVO_58_PIPELINE] QUANTUM_COGNITION :: UNIFIED_STREAM :: GOD_CODE=527.5184818492612
// L104 ASI â€” SIMD-Accelerated Vector & Matrix Operations
//
// SIMDVector (vDSP-powered ops, FFT) and AcceleratedMatrix
// (BLAS cblas_dgemm / cblas_dgemv, transpose, norms).
//
// Extracted from L104Native.swift lines 860-1092
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

import AppKit
import Foundation
import Accelerate
import simd
import NaturalLanguage

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// âš¡ SIMD-ACCELERATED VECTOR OPERATIONS (Apple Unified Architecture)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// SIMD-optimized vector for high-performance ASI computations
struct SIMDVector {
    private var storage: [Double]
    var count: Int { storage.count }

    init(_ values: [Double]) { self.storage = values }
    init(repeating value: Double, count: Int) { self.storage = Array(repeating: value, count: count) }
    init(random count: Int, range: ClosedRange<Double> = -1...1) {
        self.storage = (0..<count).map { _ in Double.random(in: range) }
    }

    subscript(index: Int) -> Double {
        get { storage[index] }
        set { storage[index] = newValue }
    }

    var array: [Double] { storage }

    /// SIMD-accelerated magnitude using vDSP
    var magnitude: Double {
        var result: Double = 0
        vDSP_svesqD(storage, 1, &result, vDSP_Length(storage.count))
        return sqrt(result)
    }

    /// SIMD-accelerated dot product
    func dot(_ other: SIMDVector) -> Double {
        guard count == other.count else { return 0 }
        var result: Double = 0
        vDSP_dotprD(storage, 1, other.storage, 1, &result, vDSP_Length(count))
        return result
    }

    /// SIMD-accelerated addition
    static func + (lhs: SIMDVector, rhs: SIMDVector) -> SIMDVector {
        guard lhs.count == rhs.count else { return lhs }
        var result = [Double](repeating: 0, count: lhs.count)
        vDSP_vaddD(lhs.storage, 1, rhs.storage, 1, &result, 1, vDSP_Length(lhs.count))
        return SIMDVector(result)
    }

    /// SIMD-accelerated subtraction
    static func - (lhs: SIMDVector, rhs: SIMDVector) -> SIMDVector {
        guard lhs.count == rhs.count else { return lhs }
        var result = [Double](repeating: 0, count: lhs.count)
        vDSP_vsubD(rhs.storage, 1, lhs.storage, 1, &result, 1, vDSP_Length(lhs.count))
        return SIMDVector(result)
    }

    /// SIMD-accelerated scalar multiply
    static func * (lhs: SIMDVector, rhs: Double) -> SIMDVector {
        var result = [Double](repeating: 0, count: lhs.count)
        var scalar = rhs
        vDSP_vsmulD(lhs.storage, 1, &scalar, &result, 1, vDSP_Length(lhs.count))
        return SIMDVector(result)
    }

    /// SIMD-accelerated element-wise multiply
    static func * (lhs: SIMDVector, rhs: SIMDVector) -> SIMDVector {
        guard lhs.count == rhs.count else { return lhs }
        var result = [Double](repeating: 0, count: lhs.count)
        vDSP_vmulD(lhs.storage, 1, rhs.storage, 1, &result, 1, vDSP_Length(lhs.count))
        return SIMDVector(result)
    }

    /// SIMD-accelerated normalization
    var normalized: SIMDVector {
        let mag = magnitude
        guard mag > 0 else { return self }
        var result = [Double](repeating: 0, count: count)
        var divisor = mag
        vDSP_vsdivD(storage, 1, &divisor, &result, 1, vDSP_Length(count))
        return SIMDVector(result)
    }

    /// Cosine similarity using SIMD
    func cosineSimilarity(_ other: SIMDVector) -> Double {
        let denom = magnitude * other.magnitude
        return denom > 0 ? dot(other) / denom : 0
    }

    /// Mean value using vDSP
    var mean: Double {
        var result: Double = 0
        vDSP_meanvD(storage, 1, &result, vDSP_Length(count))
        return result
    }

    /// Standard deviation using vDSP
    var stdDev: Double {
        var meanVal: Double = 0
        var stdDevVal: Double = 0
        vDSP_normalizeD(storage, 1, nil, 1, &meanVal, &stdDevVal, vDSP_Length(count))
        return stdDevVal
    }

    // â”€â”€â”€ Cached FFT Setups (avoid create/destroy per call) â”€â”€â”€
    private static var fftSetupCache: [vDSP_Length: OpaquePointer] = [:]
    private static let fftCacheLock = NSLock()

    private static func cachedFFTSetup(log2n: vDSP_Length) -> OpaquePointer? {
        fftCacheLock.lock()
        defer { fftCacheLock.unlock() }
        if let existing = fftSetupCache[log2n] { return existing }
        guard let setup = vDSP_create_fftsetupD(log2n, FFTRadix(kFFTRadix2)) else { return nil }
        fftSetupCache[log2n] = setup
        return setup
    }

    /// Fast Fourier Transform using vDSP (cached setup)
    func fft() -> [Complex] {
        let n = count
        let log2n = vDSP_Length(log2(Double(n)))
        guard let fftSetup = SIMDVector.cachedFFTSetup(log2n: log2n) else {
            return storage.map { Complex($0, 0) }
        }

        var realPart = storage
        var imagPart = [Double](repeating: 0, count: n)
        let result: [Complex] = realPart.withUnsafeMutableBufferPointer { realBuf in
            imagPart.withUnsafeMutableBufferPointer { imagBuf in
                var splitComplex = DSPDoubleSplitComplex(realp: realBuf.baseAddress!, imagp: imagBuf.baseAddress!)
                vDSP_fft_zipD(fftSetup, &splitComplex, 1, log2n, FFTDirection(kFFTDirection_Forward))
                return (0..<n).map { Complex(realBuf[$0], imagBuf[$0]) }
            }
        }
        return result
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ§® ACCELERATE-POWERED MATRIX ENGINE
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// BLAS/LAPACK-accelerated matrix operations
struct AcceleratedMatrix {
    private var data: [Double]
    let rows: Int
    let cols: Int

    init(rows: Int, cols: Int, fill: Double = 0) {
        self.rows = rows
        self.cols = cols
        self.data = Array(repeating: fill, count: rows * cols)
    }

    init(rows: Int, cols: Int, data: [Double]) {
        self.rows = rows
        self.cols = cols
        self.data = data
    }

    static func identity(_ size: Int) -> AcceleratedMatrix {
        var mat = AcceleratedMatrix(rows: size, cols: size)
        for i in 0..<size { mat[i, i] = 1.0 }
        return mat
    }

    static func random(rows: Int, cols: Int, range: ClosedRange<Double> = -1...1) -> AcceleratedMatrix {
        let data = (0..<(rows * cols)).map { _ in Double.random(in: range) }
        return AcceleratedMatrix(rows: rows, cols: cols, data: data)
    }

    subscript(row: Int, col: Int) -> Double {
        get { data[row * cols + col] }
        set { data[row * cols + col] = newValue }
    }

    /// Matrix-matrix multiplication using BLAS (cblas_dgemm)
    static func * (lhs: AcceleratedMatrix, rhs: AcceleratedMatrix) -> AcceleratedMatrix {
        guard lhs.cols == rhs.rows else {
            // Return zero matrix instead of crashing â€” dimensions mismatch is a logic error upstream
            return AcceleratedMatrix(rows: lhs.rows, cols: rhs.cols)
        }

        var result = AcceleratedMatrix(rows: lhs.rows, cols: rhs.cols)

        cblas_dgemm(
            CblasRowMajor,           // Row-major order
            CblasNoTrans,            // Don't transpose A
            CblasNoTrans,            // Don't transpose B
            Int32(lhs.rows),         // M = rows of A
            Int32(rhs.cols),         // N = cols of B
            Int32(lhs.cols),         // K = cols of A = rows of B
            1.0,                     // alpha
            lhs.data,                // A
            Int32(lhs.cols),         // lda
            rhs.data,                // B
            Int32(rhs.cols),         // ldb
            0.0,                     // beta
            &result.data,            // C
            Int32(rhs.cols)          // ldc
        )

        return result
    }

    /// Matrix-vector multiplication
    func multiply(_ vector: SIMDVector) -> SIMDVector {
        guard cols == vector.count else { return vector }
        var result = [Double](repeating: 0, count: rows)
        cblas_dgemv(
            CblasRowMajor,
            CblasNoTrans,
            Int32(rows),
            Int32(cols),
            1.0,
            data,
            Int32(cols),
            vector.array,
            1,
            0.0,
            &result,
            1
        )
        return SIMDVector(result)
    }

    /// Frobenius norm using vDSP
    var frobeniusNorm: Double {
        var result: Double = 0
        vDSP_svesqD(data, 1, &result, vDSP_Length(data.count))
        return sqrt(result)
    }

    /// Transpose
    var transposed: AcceleratedMatrix {
        var result = AcceleratedMatrix(rows: cols, cols: rows)
        vDSP_mtransD(data, 1, &result.data, 1, vDSP_Length(cols), vDSP_Length(rows))
        return result
    }

    /// Trace (sum of diagonal)
    var trace: Double {
        guard rows == cols else { return 0 }
        var sum: Double = 0
        for i in 0..<rows { sum += self[i, i] }
        return sum
    }
}
