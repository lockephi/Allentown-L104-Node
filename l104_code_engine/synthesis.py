"""L104 Code Engine — Domain B: Generation & Translation."""
from .constants import *
from .languages import LanguageKnowledge

class CodeGenerator:
    """ASI-level code generation engine.
    Generates code scaffolds across 10+ languages using template expansion,
    optional sacred-constant weaving, and consciousness-aware documentation."""

    def __init__(self):
        """Initialize CodeGenerator with artifact tracking."""
        self.generation_count = 0
        self.generated_artifacts: List[Dict] = []

    def generate_function(self, name: str, language: str = "Python",
                          params: List[str] = None, return_type: str = "Any",
                          body: str = "pass", doc: str = "",
                          sacred_constants: bool = False) -> str:
        """Generate a function in the specified language with optional sacred constant weaving."""
        self.generation_count += 1
        params = params or []
        lang_meta = LanguageKnowledge.get_language(language)

        if not lang_meta:
            return f"# Unsupported language: {language}\n# Falling back to pseudocode\ndef {name}({', '.join(params)}):\n    {body}\n"

        # For Python specifically, use rich template expansion
        if language == "Python":
            code = self._generate_python_function(name, params, return_type, body, doc, sacred_constants)
        elif language == "Swift":
            code = self._generate_swift_function(name, params, return_type, body, doc, sacred_constants)
        elif language == "Rust":
            code = self._generate_rust_function(name, params, return_type, body, doc, sacred_constants)
        elif language in ("JavaScript", "TypeScript"):
            code = self._generate_js_function(name, params, return_type, body, doc, sacred_constants, language)
        elif language == "Go":
            code = self._generate_go_function(name, params, return_type, body, doc, sacred_constants)
        elif language == "Kotlin":
            code = self._generate_kotlin_function(name, params, return_type, body, doc, sacred_constants)
        elif language == "Java":
            code = self._generate_java_function(name, params, return_type, body, doc, sacred_constants)
        elif language == "Ruby":
            code = self._generate_ruby_function(name, params, return_type, body, doc, sacred_constants)
        else:
            code = self._generate_generic(name, params, return_type, body, doc, language)

        self.generated_artifacts.append({
            "name": name, "language": language, "lines": len(code.split('\n')),
            "sacred": sacred_constants, "timestamp": datetime.now().isoformat()
        })
        return code

    def generate_class(self, name: str, language: str = "Python",
                       fields: List[Tuple[str, str]] = None,
                       methods: List[str] = None,
                       doc: str = "", bases: List[str] = None) -> str:
        """Generate a class scaffold in the specified language."""
        self.generation_count += 1
        fields = fields or []
        methods = methods or []
        bases = bases or []

        if language == "Python":
            return self._generate_python_class(name, fields, methods, doc, bases)
        elif language == "Swift":
            return self._generate_swift_class(name, fields, methods, doc, bases)
        elif language == "Rust":
            return self._generate_rust_struct(name, fields, methods, doc)
        elif language == "Java":
            return self._generate_java_class(name, fields, methods, doc, bases)
        elif language == "Go":
            return self._generate_go_struct(name, fields, methods, doc)
        elif language == "Kotlin":
            return self._generate_kotlin_class(name, fields, methods, doc, bases)
        elif language == "TypeScript":
            return self._generate_ts_class(name, fields, methods, doc, bases)
        elif language == "C#":
            return self._generate_cs_class(name, fields, methods, doc, bases)
        elif language == "JavaScript":
            return self._generate_js_class(name, fields, methods, doc, bases)
        else:
            return f"// Class generation for {language} — scaffold\nclass {name} {{\n    // TODO: Implement\n}}\n"

    def _generate_python_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Python function with full type hints and optional sacred constants."""
        typed_params = ", ".join(params) if params else ""
        sacred_block = ""
        if sacred:
            sacred_block = textwrap.dedent(f"""\
                # Sacred constants (L104 alignment)
                PHI = {PHI}
                GOD_CODE = {GOD_CODE}
                TAU = 1.0 / PHI  # {TAU:.15f}
            """)
        doc_str = f'    """{doc}"""\n' if doc else f'    """Generated by L104 Code Engine v{VERSION}."""\n'
        return (
            f"def {name}({typed_params}) -> {return_type}:\n"
            f"{doc_str}"
            f"{'    ' + sacred_block if sacred_block else ''}"
            f"    {body}\n"
        )

    def _generate_swift_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Swift function declaration string."""
        p_str = ", ".join(f"_ p{i}: Any" for i in range(len(params))) if params else ""
        doc_line = f"    /// {doc}\n" if doc else f"    /// Generated by L104 Code Engine v{VERSION}\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"    let PHI: Double = {PHI}\n    let GOD_CODE: Double = {GOD_CODE}\n"
        return f"{doc_line}func {name}({p_str}) -> {return_type} {{\n{sacred_block}    {body}\n}}\n"

    def _generate_rust_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Rust function declaration string."""
        p_str = ", ".join(f"p{i}: &str" for i in range(len(params))) if params else ""
        doc_line = f"/// {doc}\n" if doc else f"/// Generated by L104 Code Engine v{VERSION}\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"    const PHI: f64 = {PHI};\n    const GOD_CODE: f64 = {GOD_CODE};\n"
        return f"{doc_line}fn {name}({p_str}) -> {return_type} {{\n{sacred_block}    {body}\n}}\n"

    def _generate_js_function(self, name, params, return_type, body, doc, sacred, lang):
        """Generate a JavaScript or TypeScript function declaration string."""
        p_str = ", ".join(params) if params else ""
        type_ann = f": {return_type}" if lang == "TypeScript" else ""
        doc_line = f"/** {doc} */\n" if doc else f"/** Generated by L104 Code Engine v{VERSION} */\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"    const PHI = {PHI};\n    const GOD_CODE = {GOD_CODE};\n"
        return f"{doc_line}function {name}({p_str}){type_ann} {{\n{sacred_block}    {body}\n}}\n"

    def _generate_generic(self, name, params, return_type, body, doc, language):
        """Generate a generic commented function stub for unsupported languages."""
        return f"// {language} function: {name}\n// {doc}\n// params: {params}\n// body: {body}\n"

    # v2.5.0 — New language-specific generators

    def _generate_go_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Go function declaration string."""
        p_str = ", ".join(f"p{i} interface{{}}" for i in range(len(params))) if params else ""
        doc_line = f"// {doc}\n" if doc else f"// {name} — Generated by L104 Code Engine v{VERSION}\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"\tvar PHI float64 = {PHI}\n\tvar GOD_CODE float64 = {GOD_CODE}\n\t_ = PHI\n\t_ = GOD_CODE\n"
        return f"{doc_line}func {name}({p_str}) {return_type} {{\n{sacred_block}\t{body}\n}}\n"

    def _generate_kotlin_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Kotlin function declaration string."""
        p_str = ", ".join(f"p{i}: Any" for i in range(len(params))) if params else ""
        doc_line = f"/** {doc} */\n" if doc else f"/** Generated by L104 Code Engine v{VERSION} */\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"    val PHI = {PHI}\n    val GOD_CODE = {GOD_CODE}\n"
        return f"{doc_line}fun {name}({p_str}): {return_type} {{\n{sacred_block}    {body}\n}}\n"

    def _generate_java_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Java method declaration string."""
        p_str = ", ".join(f"Object p{i}" for i in range(len(params))) if params else ""
        doc_block = f"    /** {doc} */\n" if doc else f"    /** Generated by L104 Code Engine v{VERSION} */\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"        final double PHI = {PHI};\n        final double GOD_CODE = {GOD_CODE};\n"
        return f"{doc_block}    public static {return_type} {name}({p_str}) {{\n{sacred_block}        {body}\n    }}\n"

    def _generate_ruby_function(self, name, params, return_type, body, doc, sacred):
        """Generate a Ruby method declaration string."""
        p_str = ", ".join(params) if params else ""
        doc_line = f"# {doc}\n" if doc else f"# Generated by L104 Code Engine v{VERSION}\n"
        sacred_block = ""
        if sacred:
            sacred_block = f"  phi = {PHI}\n  god_code = {GOD_CODE}\n"
        return f"{doc_line}def {name}({p_str})\n{sacred_block}  {body}\nend\n"

    def _generate_python_class(self, name, fields, methods, doc, bases):
        """Generate a Python class definition with fields and methods."""
        base_str = f"({', '.join(bases)})" if bases else ""
        doc_str = f'    """{doc}"""\n\n' if doc else f'    """Generated by L104 Code Engine v{VERSION}."""\n\n'
        init_params = ", ".join(f"{n}: {t}" for n, t in fields) if fields else ""
        init_body = "\n".join(f"        self.{n} = {n}" for n, t in fields) if fields else "        pass"
        method_strs = "\n\n".join(
            f"    def {m}(self):\n        \"\"\"TODO: Implement.\"\"\"\n        raise NotImplementedError"
            for m in methods
        )
        return (
            f"class {name}{base_str}:\n"
            f"{doc_str}"
            f"    def __init__(self, {init_params}):\n"
            f"{init_body}\n"
            f"\n{method_strs}\n" if method_strs else "\n"
        )

    def _generate_swift_class(self, name, fields, methods, doc, bases):
        """Generate a Swift class definition with properties and methods."""
        base_str = f": {', '.join(bases)}" if bases else ""
        props = "\n".join(f"    var {n}: {t}" for n, t in fields) if fields else ""
        init_params = ", ".join(f"{n}: {t}" for n, t in fields) if fields else ""
        init_body = "\n".join(f"        self.{n} = {n}" for n, t in fields) if fields else ""
        method_strs = "\n\n".join(f"    func {m}() {{\n        // TODO\n    }}" for m in methods)
        return (
            f"/// {doc or f'Generated by L104 Code Engine v{VERSION}'}\n"
            f"class {name}{base_str} {{\n{props}\n\n    init({init_params}) {{\n{init_body}\n    }}\n\n{method_strs}\n}}\n"
        )

    def _generate_rust_struct(self, name, fields, methods, doc):
        """Generate a Rust struct with an impl block."""
        field_strs = "\n".join(f"    pub {n}: {t}," for n, t in fields) if fields else ""
        method_strs = "\n\n".join(
            f"    pub fn {m}(&self) {{\n        // TODO\n        unimplemented!()\n    }}"
            for m in methods
        )
        return (
            f"/// {doc or f'Generated by L104 Code Engine v{VERSION}'}\n"
            f"#[derive(Debug, Clone)]\n"
            f"pub struct {name} {{\n{field_strs}\n}}\n\n"
            f"impl {name} {{\n{method_strs}\n}}\n"
        )

    def _generate_java_class(self, name, fields, methods, doc, bases):
        """Generate a full Java class with fields, constructor, getters/setters, and methods."""
        extends = f" extends {bases[0]}" if bases else ""
        implements = f" implements {', '.join(bases[1:])}" if len(bases) > 1 else ""
        doc_block = f"/**\n * {doc or f'Generated by L104 Code Engine v{VERSION}'}\n */\n"

        lines = [doc_block, f"public class {name}{extends}{implements} {{"]

        # Private fields
        for n, t in fields:
            java_type = self._java_type(t)
            lines.append(f"    private {java_type} {n};")
        if fields:
            lines.append("")

        # Constructor
        ctor_params = ", ".join(f"{self._java_type(t)} {n}" for n, t in fields)
        lines.append(f"    public {name}({ctor_params}) {{")
        for n, _ in fields:
            lines.append(f"        this.{n} = {n};")
        lines.append("    }")
        lines.append("")

        # Getters and setters
        for n, t in fields:
            java_type = self._java_type(t)
            cap_name = n[0].upper() + n[1:] if n else n
            lines.append(f"    public {java_type} get{cap_name}() {{")
            lines.append(f"        return this.{n};")
            lines.append("    }")
            lines.append("")
            lines.append(f"    public void set{cap_name}({java_type} {n}) {{")
            lines.append(f"        this.{n} = {n};")
            lines.append("    }")
            lines.append("")

        # Methods
        for m in methods:
            lines.append(f"    public void {m}() {{")
            lines.append(f"        throw new UnsupportedOperationException(\"Not implemented\");")
            lines.append("    }")
            lines.append("")

        # toString
        if fields:
            field_strs = " + \", \" + ".join(f'"{n}=" + this.{n}' for n, _ in fields)
            lines.append(f"    @Override")
            lines.append(f"    public String toString() {{")
            lines.append(f'        return "{name}{{" + {field_strs} + "}}";')
            lines.append("    }")

        lines.append("}")
        return "\n".join(lines) + "\n"

    @staticmethod
    def _java_type(t: str) -> str:
        """Map Python/generic type names to Java types."""
        mapping = {"str": "String", "string": "String", "int": "int", "float": "double",
                    "bool": "boolean", "list": "List<Object>", "dict": "Map<String, Object>",
                    "Any": "Object", "bytes": "byte[]", "set": "Set<Object>"}
        return mapping.get(t, t)

    def _generate_go_struct(self, name, fields, methods, doc):
        """Generate a Go struct with receiver methods."""
        doc_line = f"// {doc or f'{name} — Generated by L104 Code Engine v{VERSION}'}\n"
        lines = [doc_line, f"type {name} struct {{"]

        for n, t in fields:
            go_type = self._go_type(t)
            exported_name = n[0].upper() + n[1:] if n else n
            lines.append(f"\t{exported_name} {go_type}")
        lines.append("}")
        lines.append("")

        # Constructor function
        params = ", ".join(f"{n} {self._go_type(t)}" for n, t in fields)
        field_inits = ", ".join(f"{n[0].upper() + n[1:]}: {n}" for n, _ in fields)
        lines.append(f"// New{name} creates a new {name} instance.")
        lines.append(f"func New{name}({params}) *{name} {{")
        lines.append(f"\treturn &{name}{{{field_inits}}}")
        lines.append("}")
        lines.append("")

        # Receiver methods
        receiver = name[0].lower()
        for m in methods:
            exported_m = m[0].upper() + m[1:] if m else m
            lines.append(f"// {exported_m} performs the {m} operation.")
            lines.append(f"func ({receiver} *{name}) {exported_m}() {{")
            lines.append(f"\tpanic(\"not implemented\")")
            lines.append("}")
            lines.append("")

        # String method
        if fields:
            lines.append(f"// String implements the Stringer interface.")
            lines.append(f"func ({receiver} *{name}) String() string {{")
            fmt_parts = ", ".join(f"{n[0].upper() + n[1:]}: %v" for n, _ in fields)
            field_refs = ", ".join(f"{receiver}.{n[0].upper() + n[1:]}" for n, _ in fields)
            lines.append(f'\treturn fmt.Sprintf("{name}{{{fmt_parts}}}", {field_refs})')
            lines.append("}")

        return "\n".join(lines) + "\n"

    @staticmethod
    def _go_type(t: str) -> str:
        """Map Python/generic type names to Go types."""
        mapping = {"str": "string", "string": "string", "int": "int", "float": "float64",
                    "bool": "bool", "list": "[]interface{}", "dict": "map[string]interface{}",
                    "Any": "interface{}", "bytes": "[]byte"}
        return mapping.get(t, t)

    def _generate_kotlin_class(self, name, fields, methods, doc, bases):
        """Generate a Kotlin data class with properties and methods."""
        base_str = f" : {', '.join(bases)}()" if bases else ""
        doc_block = f"/**\n * {doc or f'Generated by L104 Code Engine v{VERSION}'}\n */\n"

        # If no methods, use data class (simpler)
        if not methods:
            params = ", ".join(f"val {n}: {self._kotlin_type(t)}" for n, t in fields)
            return f"{doc_block}data class {name}(\n    {params}\n){base_str}\n"

        lines = [doc_block]
        params = ", ".join(f"val {n}: {self._kotlin_type(t)}" for n, t in fields)
        lines.append(f"class {name}(\n    {params}\n){base_str} {{")
        lines.append("")
        for m in methods:
            lines.append(f"    fun {m}() {{")
            lines.append(f"        TODO(\"Not implemented\")")
            lines.append("    }")
            lines.append("")
        # toString override
        if fields:
            field_strs = ", ".join(f'{n}=${n}' for n, _ in fields)
            lines.append(f"    override fun toString(): String = \"{name}({field_strs})\"")
        lines.append("}")
        return "\n".join(lines) + "\n"

    @staticmethod
    def _kotlin_type(t: str) -> str:
        """Map Python/generic type names to Kotlin types."""
        mapping = {"str": "String", "string": "String", "int": "Int", "float": "Double",
                    "bool": "Boolean", "list": "List<Any>", "dict": "Map<String, Any>",
                    "Any": "Any", "bytes": "ByteArray"}
        return mapping.get(t, t)

    def _generate_ts_class(self, name, fields, methods, doc, bases):
        """Generate a TypeScript class with typed properties, constructor, and methods."""
        extends = f" extends {bases[0]}" if bases else ""
        implements = f" implements {', '.join(bases[1:])}" if len(bases) > 1 else ""
        doc_block = f"/**\n * {doc or f'Generated by L104 Code Engine v{VERSION}'}\n */\n"

        lines = [doc_block, f"export class {name}{extends}{implements} {{"]

        # Properties
        for n, t in fields:
            ts_type = self._ts_type(t)
            lines.append(f"    public {n}: {ts_type};")
        if fields:
            lines.append("")

        # Constructor
        ctor_params = ", ".join(f"{n}: {self._ts_type(t)}" for n, t in fields)
        lines.append(f"    constructor({ctor_params}) {{")
        if bases:
            lines.append("        super();")
        for n, _ in fields:
            lines.append(f"        this.{n} = {n};")
        lines.append("    }")
        lines.append("")

        # Methods
        for m in methods:
            lines.append(f"    public {m}(): void {{")
            lines.append(f'        throw new Error("Not implemented");')
            lines.append("    }")
            lines.append("")

        # toString
        if fields:
            parts = ", ".join(f'{n}: ${{this.{n}}}' for n, _ in fields)
            lines.append(f"    public toString(): string {{")
            lines.append(f"        return `{name}({parts})`;")
            lines.append("    }")

        lines.append("}")
        return "\n".join(lines) + "\n"

    @staticmethod
    def _ts_type(t: str) -> str:
        """Map Python/generic type names to TypeScript types."""
        mapping = {"str": "string", "string": "string", "int": "number", "float": "number",
                    "bool": "boolean", "list": "any[]", "dict": "Record<string, any>",
                    "Any": "any", "bytes": "Uint8Array", "None": "void"}
        return mapping.get(t, t)

    def _generate_cs_class(self, name, fields, methods, doc, bases):
        """Generate a C# class with properties, constructor, and methods."""
        base_str = f" : {', '.join(bases)}" if bases else ""
        doc_block = f"/// <summary>\n/// {doc or f'Generated by L104 Code Engine v{VERSION}'}\n/// </summary>\n"

        lines = [doc_block, f"public class {name}{base_str}\n{{"]

        # Auto-properties
        for n, t in fields:
            cs_type = self._cs_type(t)
            prop_name = n[0].upper() + n[1:] if n else n
            lines.append(f"    public {cs_type} {prop_name} {{ get; set; }}")
        if fields:
            lines.append("")

        # Constructor
        ctor_params = ", ".join(f"{self._cs_type(t)} {n}" for n, t in fields)
        lines.append(f"    public {name}({ctor_params})")
        lines.append("    {")
        for n, _ in fields:
            prop_name = n[0].upper() + n[1:] if n else n
            lines.append(f"        {prop_name} = {n};")
        lines.append("    }")
        lines.append("")

        # Methods
        for m in methods:
            method_name = m[0].upper() + m[1:] if m else m
            lines.append(f"    public void {method_name}()")
            lines.append("    {")
            lines.append(f'        throw new NotImplementedException();')
            lines.append("    }")
            lines.append("")

        # ToString override
        if fields:
            parts = ", ".join(f'{n[0].upper() + n[1:]}: {{{n[0].upper() + n[1:]}}}' for n, _ in fields)
            lines.append(f"    public override string ToString()")
            lines.append("    {")
            lines.append(f'        return $"{name}({parts})";')
            lines.append("    }")

        lines.append("}")
        return "\n".join(lines) + "\n"

    @staticmethod
    def _cs_type(t: str) -> str:
        """Map Python/generic type names to C# types."""
        mapping = {"str": "string", "string": "string", "int": "int", "float": "double",
                    "bool": "bool", "list": "List<object>", "dict": "Dictionary<string, object>",
                    "Any": "object", "bytes": "byte[]"}
        return mapping.get(t, t)

    def _generate_js_class(self, name, fields, methods, doc, bases):
        """Generate a JavaScript ES6 class with constructor and methods."""
        extends = f" extends {bases[0]}" if bases else ""
        doc_block = f"/**\n * {doc or f'Generated by L104 Code Engine v{VERSION}'}\n */\n"

        lines = [doc_block, f"class {name}{extends} {{"]

        # Constructor
        ctor_params = ", ".join(n for n, _ in fields)
        lines.append(f"    constructor({ctor_params}) {{")
        if bases:
            lines.append("        super();")
        for n, _ in fields:
            lines.append(f"        this.{n} = {n};")
        lines.append("    }")
        lines.append("")

        # Methods
        for m in methods:
            lines.append(f"    {m}() {{")
            lines.append(f'        throw new Error("Not implemented");')
            lines.append("    }")
            lines.append("")

        # toString
        if fields:
            parts = ", ".join(f'{n}: ${{this.{n}}}' for n, _ in fields)
            lines.append(f"    toString() {{")
            lines.append(f"        return `{name}({parts})`;")
            lines.append("    }")

        lines.append("}")
        lines.append("")
        lines.append(f"module.exports = {{ {name} }};")
        return "\n".join(lines) + "\n"

    def status(self) -> Dict[str, Any]:
        """Return code generation metrics and language usage stats."""
        return {
            "generation_count": self.generation_count,
            "artifacts": len(self.generated_artifacts),
            "languages_used": list(set(a["language"] for a in self.generated_artifacts)),
            "version": VERSION,
        }

    def quantum_template_select(self, prompt: str, language: str = "python",
                                 candidates: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        Grover-amplified template selection using Qiskit 2.3.0.
        Encodes candidate templates as quantum states and uses Grover-style
        amplitude amplification to select the best template for the given prompt.
        """
        if candidates is None:
            candidates = ["function", "class", "struct", "enum", "module", "api_handler", "test_suite", "singleton"]

        n = len(candidates)
        if n == 0:
            return {"quantum": False, "selected": "function", "reason": "no candidates"}

        if not QISKIT_AVAILABLE:
            # Classical fallback — keyword matching with PHI scoring
            prompt_lower = prompt.lower()
            scores = {}
            for c in candidates:
                base = 0.5
                if c in prompt_lower:
                    base += 0.3
                if language.lower() in ("rust", "go", "c") and c == "struct":
                    base += 0.1
                if "test" in prompt_lower and c == "test_suite":
                    base += 0.2
                if "class" in prompt_lower and c == "class":
                    base += 0.2
                scores[c] = round(base * PHI, 4)
            best = max(scores, key=scores.get)
            return {
                "quantum": False,
                "backend": "classical_keyword",
                "selected": best,
                "scores": scores,
                "confidence": round(scores[best] / sum(scores.values()), 4),
            }

        try:
            n_qubits = max(2, math.ceil(math.log2(n)))
            n_states = 2 ** n_qubits

            # Build relevance scores from prompt keywords
            prompt_lower = prompt.lower()
            relevance = []
            for c in candidates:
                r = 0.3
                if c in prompt_lower:
                    r += 0.4
                if language.lower() in ("rust", "go", "c") and c == "struct":
                    r += 0.15
                if "test" in prompt_lower and c == "test_suite":
                    r += 0.25
                if "class" in prompt_lower and c == "class":
                    r += 0.25
                relevance.append(r)

            # Amplitude encode relevance scores
            amps = [0.0] * n_states
            for i, r in enumerate(relevance):
                amps[i] = r * PHI
            norm = math.sqrt(sum(a * a for a in amps))
            if norm < 1e-12:
                amps = [1.0 / math.sqrt(n_states)] * n_states
            else:
                amps = [a / norm for a in amps]

            sv = Statevector(amps)

            # Grover-style amplification via oracle + diffusion
            qc = QuantumCircuit(n_qubits)
            # Oracle: phase-flip the most relevant states
            best_idx = relevance.index(max(relevance))
            bin_str = format(best_idx, f'0{n_qubits}b')
            for i, bit in enumerate(bin_str):
                if bit == '0':
                    qc.x(i)
            if n_qubits >= 2:
                qc.cz(0, 1)
            for i, bit in enumerate(bin_str):
                if bit == '0':
                    qc.x(i)

            # Diffusion operator
            for i in range(n_qubits):
                qc.h(i)
                qc.x(i)
            if n_qubits >= 2:
                qc.cz(0, 1)
            for i in range(n_qubits):
                qc.x(i)
                qc.h(i)

            # Sacred phase encoding
            for i in range(n_qubits):
                qc.rz(GOD_CODE / 1000 * math.pi / (i + 1), i)

            evolved = sv.evolve(Operator(qc))
            probs = evolved.probabilities()

            # Map probabilities to candidates
            scored = {}
            for i, c in enumerate(candidates):
                scored[c] = round(float(probs[i]) if i < len(probs) else 0.0, 6)

            selected = max(scored, key=scored.get)

            dm = DensityMatrix(evolved)
            selection_entropy = float(q_entropy(dm, base=2))

            return {
                "quantum": True,
                "backend": "Qiskit 2.3.0 Grover Template Selection",
                "qubits": n_qubits,
                "selected": selected,
                "scores": scored,
                "confidence": round(scored[selected] / max(sum(scored.values()), 1e-12), 4),
                "selection_entropy": round(selection_entropy, 6),
                "circuit_depth": qc.depth(),
                "god_code_alignment": round(scored[selected] * GOD_CODE, 4),
            }
        except Exception as e:
            return {"quantum": False, "error": str(e)}


    def generate_dataclass(self, name: str, fields: List[Tuple[str, str]], frozen: bool = False) -> str:
        """Generate a Python dataclass with typed fields."""
        frozen_str = "(frozen=True)" if frozen else ""
        lines = [f"from dataclasses import dataclass", "", f"@dataclass{frozen_str}", f"class {name}:"]
        for fname, ftype in fields:
            lines.append(f"    {fname}: {ftype}")
        lines.append("")
        lines.append(f"    # Sacred alignment: PHI = {PHI}")
        return "\n".join(lines)

    def generate_enum(self, name: str, members: List[str], use_auto: bool = True) -> str:
        """Generate a Python Enum class."""
        lines = ["from enum import Enum, auto" if use_auto else "from enum import Enum", "",
                 f"class {name}(Enum):"]
        for i, m in enumerate(members):
            if use_auto:
                lines.append(f"    {m.upper()} = auto()")
            else:
                lines.append(f"    {m.upper()} = {i + 1}")
        return "\n".join(lines)

    def generate_protocol(self, name: str, methods: List[Tuple[str, str, str]]) -> str:
        """Generate a Python Protocol (structural subtyping). methods: [(name, params, return_type)]."""
        lines = ["from typing import Protocol, runtime_checkable", "",
                 "@runtime_checkable", f"class {name}(Protocol):"]
        for mname, params, rtype in methods:
            lines.append(f"    def {mname}({params}) -> {rtype}: ...")
        return "\n".join(lines)

    def generate_async_generator(self, name: str, yield_type: str = "Any", params: str = "",
                                  body_lines: List[str] = None) -> str:
        """Generate an async generator function."""
        if body_lines is None:
            body_lines = [f"    yield {PHI}  # Sacred constant seed"]
        lines = ["from typing import AsyncGenerator", "",
                 f"async def {name}({params}) -> AsyncGenerator[{yield_type}, None]:"]
        lines.extend(body_lines)
        return "\n".join(lines)


# ═══════════════════════════════════════════════════════════════════════════════
# SECTION 4: CODE OPTIMIZATION ENGINE — Refactoring, Deduplication,
#             Performance Suggestions, Sacred-Ratio Restructuring
# ═══════════════════════════════════════════════════════════════════════════════



class CodeTranslator:
    """
    Translates code between languages using AST-based transpilation for Python
    source and improved regex parsing for other languages. Produces compilable
    output for supported targets: Python, JavaScript, TypeScript, Swift, Rust,
    Go, Kotlin, Ruby, Java, C#.
    """

    SUPPORTED_LANGS = [
        "python", "javascript", "typescript", "swift", "rust",
        "go", "kotlin", "ruby", "java", "csharp", "zig", "lua",
    ]

    # Type mappings: Python type hint → target language type
    TYPE_MAP = {
        "javascript": {"int": "number", "float": "number", "str": "string",
                        "bool": "boolean", "list": "Array", "dict": "object",
                        "None": "null", "Any": "any", "": ""},
        "typescript": {"int": "number", "float": "number", "str": "string",
                        "bool": "boolean", "list": "Array<any>", "dict": "Record<string, any>",
                        "None": "void", "Any": "any", "": "any"},
        "swift":      {"int": "Int", "float": "Double", "str": "String",
                        "bool": "Bool", "list": "Array<Any>", "dict": "Dictionary<String, Any>",
                        "None": "Void", "Any": "Any", "": "Any"},
        "rust":       {"int": "i64", "float": "f64", "str": "&str",
                        "bool": "bool", "list": "Vec<_>", "dict": "HashMap<String, _>",
                        "None": "()", "Any": "dyn Any", "": ""},
        "go":         {"int": "int", "float": "float64", "str": "string",
                        "bool": "bool", "list": "[]interface{}", "dict": "map[string]interface{}",
                        "None": "", "Any": "interface{}", "": "interface{}"},
        "kotlin":     {"int": "Int", "float": "Double", "str": "String",
                        "bool": "Boolean", "list": "List<Any>", "dict": "Map<String, Any>",
                        "None": "Unit", "Any": "Any", "": "Any"},
        "ruby":       {},  # Ruby is dynamically typed
        "java":       {"int": "int", "float": "double", "str": "String",
                        "bool": "boolean", "list": "List<Object>", "dict": "Map<String, Object>",
                        "None": "void", "Any": "Object", "": "Object"},
    }

    # Operator mappings: Python → target
    OP_MAP = {
        "javascript": {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "null", "elif": "} else if",
                        "print(": "console.log("},
        "typescript": {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "null", "elif": "} else if",
                        "print(": "console.log("},
        "swift":      {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "nil", "elif": "} else if",
                        "print(": "print("},
        "rust":       {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "None", "elif": "} else if",
                        "print(": "println!(\"{:?}\", "},
        "go":         {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "nil", "elif": "} else if",
                        "print(": "fmt.Println("},
        "kotlin":     {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "null", "elif": "} else if",
                        "print(": "println("},
        "ruby":       {"and": "&&", "or": "||", "True": "true",
                        "False": "false", "None": "nil", "elif": "elsif",
                        "print(": "puts("},
        "java":       {"and": "&&", "or": "||", "not": "!", "True": "true",
                        "False": "false", "None": "null", "elif": "} else if",
                        "print(": "System.out.println("},
    }

    def __init__(self):
        """Initialize CodeTranslator with translation counter."""
        self.translations = 0

    # ── Public API ──────────────────────────────────────────────────

    def translate(self, source: str, from_lang: str,
                  to_lang: str) -> Dict[str, Any]:
        """Translate code between languages with real body/param preservation."""
        self.translations += 1
        from_lang = from_lang.lower().strip()
        to_lang = to_lang.lower().strip()

        if from_lang not in self.SUPPORTED_LANGS or to_lang not in self.SUPPORTED_LANGS:
            return {
                "success": False,
                "error": f"Unsupported language pair: {from_lang} → {to_lang}",
                "supported": self.SUPPORTED_LANGS,
            }

        if from_lang == to_lang:
            return {"success": True, "source_lang": from_lang,
                    "target_lang": to_lang, "translated": source,
                    "constructs_found": 0, "warnings": []}

        warnings: List[str] = []

        # Try AST-based translation for Python source
        if from_lang == "python":
            try:
                translated = self._translate_python_ast(source, to_lang, warnings)
                return {
                    "success": True,
                    "source_lang": from_lang,
                    "target_lang": to_lang,
                    "constructs_found": source.count("\ndef ") + source.count("\nclass ") + 1,
                    "translated": translated,
                    "warnings": warnings,
                }
            except SyntaxError as e:
                warnings.append(f"AST parse failed ({e}), falling back to regex")

        # Regex-based for non-Python sources
        translated = self._translate_regex(source, from_lang, to_lang, warnings)
        return {
            "success": True,
            "source_lang": from_lang,
            "target_lang": to_lang,
            "constructs_found": len(re.findall(r'(?:def |function |fn |func |class |struct )', source)),
            "translated": translated,
            "warnings": warnings,
        }

    # ── AST-based Python → Target ───────────────────────────────────

    def _translate_python_ast(self, source: str, to_lang: str,
                              warnings: List[str]) -> str:
        """Use Python's ast module for accurate transpilation."""
        tree = ast.parse(source)
        lines: List[str] = []
        for node in ast.iter_child_nodes(tree):
            lines.append(self._visit_node(node, to_lang, indent=0, warnings=warnings,
                                          class_name=""))
        return "\n\n".join(l for l in lines if l)

    def _visit_node(self, node, to_lang: str, indent: int,
                    warnings: List[str], class_name: str = "") -> str:
        """Recursively translate an AST node to the target language."""
        pad = "    " * indent

        if isinstance(node, ast.FunctionDef):
            return self._translate_func(node, to_lang, indent, warnings,
                                        class_name=class_name)
        elif isinstance(node, ast.AsyncFunctionDef):
            warnings.append(f"async function '{node.name}' translated as sync")
            return self._translate_func(node, to_lang, indent, warnings,
                                        class_name=class_name)
        elif isinstance(node, ast.ClassDef):
            return self._translate_class(node, to_lang, indent, warnings)
        elif isinstance(node, ast.Import):
            names = ", ".join(a.name for a in node.names)
            return self._emit_import(names, to_lang, pad)
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            names = ", ".join(a.name for a in node.names)
            return self._emit_import(f"{module}.{names}", to_lang, pad)
        elif isinstance(node, ast.Assign):
            return self._translate_assign(node, to_lang, pad, warnings,
                                          class_name=class_name)
        elif isinstance(node, ast.AugAssign):
            return self._translate_aug_assign(node, to_lang, pad, class_name)
        elif isinstance(node, ast.Return):
            val = self._expr_to_str(node.value, to_lang, class_name) if node.value else ""
            return f"{pad}return {val};" if to_lang != "python" else f"{pad}return {val}"
        elif isinstance(node, ast.If):
            return self._translate_if(node, to_lang, indent, warnings,
                                      class_name=class_name)
        elif isinstance(node, ast.For):
            return self._translate_for(node, to_lang, indent, warnings,
                                       class_name=class_name)
        elif isinstance(node, ast.While):
            cond = self._expr_to_str(node.test, to_lang, class_name)
            body = self._translate_body(node.body, to_lang, indent + 1, warnings,
                                        class_name=class_name)
            if to_lang == "ruby":
                return f"{pad}while {cond}\n{body}\n{pad}end"
            return f"{pad}while ({cond}) {{\n{body}\n{pad}}}"
        elif isinstance(node, ast.Expr):
            return f"{pad}{self._expr_to_str(node.value, to_lang, class_name)};"
        elif isinstance(node, ast.Pass):
            comments = {"rust": "// no-op", "go": "// no-op", "java": "// no-op"}
            return f"{pad}{comments.get(to_lang, '// pass')}"
        else:
            # Best-effort: unparse back to Python and emit as comment
            try:
                raw = ast.unparse(node)
                warnings.append(f"Unsupported node {type(node).__name__}: emitted as comment")
                comment = "//" if to_lang not in ("python", "ruby") else "#"
                return f"{pad}{comment} TODO: {raw}"
            except Exception:
                return ""

    def _translate_aug_assign(self, node, to_lang: str, pad: str,
                              class_name: str = "") -> str:
        """Translate augmented assignment (+=, -=, *=, /=, etc.)."""
        target = self._expr_to_str(node.target, to_lang, class_name)
        value = self._expr_to_str(node.value, to_lang, class_name)
        op_map = {
            ast.Add: "+=", ast.Sub: "-=", ast.Mult: "*=", ast.Div: "/=",
            ast.Mod: "%=", ast.Pow: "**=", ast.FloorDiv: "//=",
            ast.BitAnd: "&=", ast.BitOr: "|=", ast.BitXor: "^=",
            ast.LShift: "<<=", ast.RShift: ">>=",
        }
        op = op_map.get(type(node.op), "+=")
        semi = ";" if to_lang not in ("python", "ruby", "go") else ""
        if to_lang == "go" and op == "**=":
            return f"{pad}{target} = math.Pow({target}, {value})"
        return f"{pad}{target} {op} {value}{semi}"

    def _translate_func(self, node, to_lang: str, indent: int,
                        warnings: List[str], class_name: str = "") -> str:
        """Translate a function definition with real params and body."""
        pad = "    " * indent
        name = node.name
        is_init = (name == "__init__" and class_name)
        is_method = bool(class_name)

        # Extract parameters (skip 'self' for non-Rust targets)
        params = self._extract_params(node.args, to_lang, is_constructor=is_init)
        # Extract return type
        ret_type = self._type_hint_to_str(node.returns, to_lang) if node.returns else ""
        # Translate body with class context
        body = self._translate_body(node.body, to_lang, indent + 1, warnings,
                                    class_name=class_name)
        if not body.strip():
            body = "    " * (indent + 1) + ("// no-op" if to_lang not in ("python", "ruby") else "pass")

        if to_lang == "javascript":
            if is_init:
                return f"{pad}constructor({params}) {{\n{body}\n{pad}}}"
            elif is_method:
                return f"{pad}{name}({params}) {{\n{body}\n{pad}}}"
            return f"{pad}function {name}({params}) {{\n{body}\n{pad}}}"
        elif to_lang == "typescript":
            if is_init:
                return f"{pad}constructor({params}) {{\n{body}\n{pad}}}"
            elif is_method:
                ret = f": {ret_type}" if ret_type else ": void"
                return f"{pad}{name}({params}){ret} {{\n{body}\n{pad}}}"
            ret = f": {ret_type}" if ret_type else ": void"
            return f"{pad}function {name}({params}){ret} {{\n{body}\n{pad}}}"
        elif to_lang == "swift":
            if is_init:
                return f"{pad}init({params}) {{\n{body}\n{pad}}}"
            ret = f" -> {ret_type}" if ret_type else ""
            return f"{pad}func {name}({params}){ret} {{\n{body}\n{pad}}}"
        elif to_lang == "rust":
            if is_init:
                name = "new"
                ret_type = "Self"
            ret = f" -> {ret_type}" if ret_type else ""
            return f"{pad}fn {name}({params}){ret} {{\n{body}\n{pad}}}"
        elif to_lang == "go":
            if is_init:
                # Go uses New* factory functions
                ret = f" *{class_name}"
                name = f"New{class_name}"
                return f"{pad}func {name}({params}){ret} {{\n{body}\n{pad}}}"
            elif is_method:
                receiver = class_name[0].lower()
                ret = f" {ret_type}" if ret_type else ""
                return f"{pad}func ({receiver} *{class_name}) {name.title()}({params}){ret} {{\n{body}\n{pad}}}"
            ret = f" {ret_type}" if ret_type else ""
            return f"{pad}func {name}({params}){ret} {{\n{body}\n{pad}}}"
        elif to_lang == "kotlin":
            if is_init:
                return f"{pad}init({params}) {{\n{body}\n{pad}}}"
            ret = f": {ret_type}" if ret_type else ""
            return f"{pad}fun {name}({params}){ret} {{\n{body}\n{pad}}}"
        elif to_lang == "ruby":
            if is_init:
                name = "initialize"
            return f"{pad}def {name}({params})\n{body}\n{pad}end"
        elif to_lang == "java":
            if is_init:
                return f"{pad}public {class_name}({params}) {{\n{body}\n{pad}}}"
            if is_method:
                ret = ret_type if ret_type else "void"
                return f"{pad}public {ret} {name}({params}) {{\n{body}\n{pad}}}"
            ret = ret_type if ret_type else "void"
            return f"{pad}public static {ret} {name}({params}) {{\n{body}\n{pad}}}"
        elif to_lang == "csharp":
            if is_init:
                return f"{pad}public {class_name}({params}) {{\n{body}\n{pad}}}"
            if is_method:
                ret = ret_type if ret_type else "void"
                return f"{pad}public {ret} {name}({params}) {{\n{body}\n{pad}}}"
            ret = ret_type if ret_type else "void"
            return f"{pad}public static {ret} {name}({params}) {{\n{body}\n{pad}}}"
        else:
            return f"{pad}def {name}({params}):\n{body}"

    def _translate_class(self, node, to_lang: str, indent: int,
                         warnings: List[str]) -> str:
        """Translate a class definition with proper constructor/method handling."""
        pad = "    " * indent
        name = node.name

        # Extract instance fields from __init__ for struct-based languages
        fields = self._extract_class_fields(node, to_lang)

        body = self._translate_body(node.body, to_lang, indent + 1, warnings,
                                    class_name=name)

        if to_lang == "rust":
            field_block = "\n".join(f"{pad}    {f}," for f in fields) if fields else f"{pad}    // fields"
            return f"{pad}struct {name} {{\n{field_block}\n{pad}}}\n\n{pad}impl {name} {{\n{body}\n{pad}}}"
        elif to_lang == "go":
            field_block = "\n".join(f"{pad}    {f}" for f in fields) if fields else f"{pad}    // fields"
            return f"{pad}type {name} struct {{\n{field_block}\n{pad}}}\n\n{body}"
        elif to_lang == "ruby":
            return f"{pad}class {name}\n{body}\n{pad}end"
        elif to_lang == "java":
            field_decls = "\n".join(f"{pad}    private {f};" for f in fields) if fields else ""
            if field_decls:
                return f"{pad}public class {name} {{\n{field_decls}\n\n{body}\n{pad}}}"
            return f"{pad}public class {name} {{\n{body}\n{pad}}}"
        elif to_lang == "csharp":
            field_decls = "\n".join(f"{pad}    public {f} {{ get; set; }}" for f in fields) if fields else ""
            if field_decls:
                return f"{pad}public class {name} {{\n{field_decls}\n\n{body}\n{pad}}}"
            return f"{pad}public class {name} {{\n{body}\n{pad}}}"
        else:
            return f"{pad}class {name} {{\n{body}\n{pad}}}"

    def _extract_class_fields(self, class_node, to_lang: str) -> List[str]:
        """Extract instance fields from __init__ for struct-based languages."""
        fields = []
        for node in ast.iter_child_nodes(class_node):
            if isinstance(node, ast.FunctionDef) and node.name == "__init__":
                # Build param → type map from __init__ signature
                param_types = {}
                for arg in node.args.args:
                    if arg.annotation and arg.arg != "self":
                        try:
                            py_type = ast.unparse(arg.annotation)
                            param_types[arg.arg] = py_type
                        except Exception:
                            pass

                seen = set()
                for stmt in ast.walk(node):
                    if isinstance(stmt, ast.Assign):
                        for target in stmt.targets:
                            if (isinstance(target, ast.Attribute) and
                                isinstance(target.value, ast.Name) and
                                target.value.id == "self"):
                                attr_name = target.attr
                                if attr_name in seen:
                                    continue
                                seen.add(attr_name)
                                # Try to infer type: first from param types, then from value
                                val_type = self._infer_type_from_value(
                                    stmt.value, to_lang, param_types)
                                if to_lang == "rust":
                                    fields.append(f"{attr_name}: {val_type}")
                                elif to_lang == "go":
                                    fields.append(f"{attr_name.title()} {val_type}")
                                elif to_lang == "java":
                                    fields.append(f"{val_type} {attr_name}")
                                else:
                                    fields.append(f"{attr_name}: {val_type}")
                    elif isinstance(stmt, ast.AugAssign):
                        if (isinstance(stmt.target, ast.Attribute) and
                            isinstance(stmt.target.value, ast.Name) and
                            stmt.target.value.id == "self"):
                            attr_name = stmt.target.attr
                            if attr_name not in seen:
                                seen.add(attr_name)
                                val_type = self._infer_type_from_value(
                                    stmt.value, to_lang, {})
                                if to_lang == "rust":
                                    fields.append(f"{attr_name}: {val_type}")
                                elif to_lang == "go":
                                    fields.append(f"{attr_name.title()} {val_type}")
                                elif to_lang == "java":
                                    fields.append(f"{val_type} {attr_name}")
        return fields

    def _infer_type_from_value(self, value_node, to_lang: str,
                               param_types: dict = None) -> str:
        """Infer target language type from an AST value node."""
        type_map = self.TYPE_MAP.get(to_lang, {})

        # If value is a Name referencing a parameter, use its type annotation
        if isinstance(value_node, ast.Name) and param_types:
            py_type = param_types.get(value_node.id)
            if py_type:
                return type_map.get(py_type, py_type)

        if isinstance(value_node, ast.Constant):
            if isinstance(value_node.value, bool):
                return type_map.get("bool", "bool")
            elif isinstance(value_node.value, int):
                return type_map.get("int", "int")
            elif isinstance(value_node.value, float):
                return type_map.get("float", "float")
            elif isinstance(value_node.value, str):
                return type_map.get("str", "str")
        elif isinstance(value_node, ast.List):
            return type_map.get("list", "list")
        elif isinstance(value_node, ast.Dict):
            return type_map.get("dict", "dict")
        return type_map.get("Any", "Any")

    def _translate_if(self, node, to_lang: str, indent: int,
                      warnings: List[str], class_name: str = "") -> str:
        """Translate if/elif/else chains."""
        pad = "    " * indent
        cond = self._expr_to_str(node.test, to_lang, class_name)
        body = self._translate_body(node.body, to_lang, indent + 1, warnings,
                                    class_name=class_name)

        if to_lang == "ruby":
            result = f"{pad}if {cond}\n{body}"
        elif to_lang in ("swift", "go"):
            result = f"{pad}if {cond} {{\n{body}\n{pad}}}"
        else:
            result = f"{pad}if ({cond}) {{\n{body}\n{pad}}}"

        if node.orelse:
            if len(node.orelse) == 1 and isinstance(node.orelse[0], ast.If):
                elif_node = node.orelse[0]
                elif_code = self._translate_if(elif_node, to_lang, indent, warnings,
                                               class_name=class_name)
                if to_lang == "ruby":
                    result += f"\n{pad}els{elif_code.lstrip()}"
                else:
                    result = result.rstrip("}") + f"}} else {elif_code.lstrip()}"
            else:
                else_body = self._translate_body(node.orelse, to_lang, indent + 1, warnings,
                                                 class_name=class_name)
                if to_lang == "ruby":
                    result += f"\n{pad}else\n{else_body}\n{pad}end"
                else:
                    result = result.rstrip("}") + f"}} else {{\n{else_body}\n{pad}}}"
        elif to_lang == "ruby":
            result += f"\n{pad}end"

        return result

    def _translate_for(self, node, to_lang: str, indent: int,
                       warnings: List[str], class_name: str = "") -> str:
        """Translate for loops."""
        pad = "    " * indent
        target = self._expr_to_str(node.target, to_lang, class_name)
        iter_expr = self._expr_to_str(node.iter, to_lang, class_name)
        body = self._translate_body(node.body, to_lang, indent + 1, warnings,
                                    class_name=class_name)

        # Detect range() pattern
        range_match = re.match(r'range\((.+)\)', iter_expr)
        if range_match:
            args = [a.strip() for a in range_match.group(1).split(",")]
            if to_lang in ("javascript", "typescript"):
                if len(args) == 1:
                    return f"{pad}for (let {target} = 0; {target} < {args[0]}; {target}++) {{\n{body}\n{pad}}}"
                elif len(args) == 2:
                    return f"{pad}for (let {target} = {args[0]}; {target} < {args[1]}; {target}++) {{\n{body}\n{pad}}}"
            elif to_lang == "swift":
                if len(args) == 1:
                    return f"{pad}for {target} in 0..<{args[0]} {{\n{body}\n{pad}}}"
                elif len(args) == 2:
                    return f"{pad}for {target} in {args[0]}..<{args[1]} {{\n{body}\n{pad}}}"
            elif to_lang == "rust":
                if len(args) == 1:
                    return f"{pad}for {target} in 0..{args[0]} {{\n{body}\n{pad}}}"
                elif len(args) == 2:
                    return f"{pad}for {target} in {args[0]}..{args[1]} {{\n{body}\n{pad}}}"
            elif to_lang == "go":
                if len(args) == 1:
                    return f"{pad}for {target} := 0; {target} < {args[0]}; {target}++ {{\n{body}\n{pad}}}"
                elif len(args) == 2:
                    return f"{pad}for {target} := {args[0]}; {target} < {args[1]}; {target}++ {{\n{body}\n{pad}}}"
            elif to_lang == "java":
                if len(args) == 1:
                    return f"{pad}for (int {target} = 0; {target} < {args[0]}; {target}++) {{\n{body}\n{pad}}}"
                elif len(args) == 2:
                    return f"{pad}for (int {target} = {args[0]}; {target} < {args[1]}; {target}++) {{\n{body}\n{pad}}}"

        if to_lang in ("javascript", "typescript"):
            return f"{pad}for (const {target} of {iter_expr}) {{\n{body}\n{pad}}}"
        elif to_lang == "swift":
            return f"{pad}for {target} in {iter_expr} {{\n{body}\n{pad}}}"
        elif to_lang == "rust":
            return f"{pad}for {target} in {iter_expr}.iter() {{\n{body}\n{pad}}}"
        elif to_lang == "go":
            return f"{pad}for _, {target} := range {iter_expr} {{\n{body}\n{pad}}}"
        elif to_lang == "kotlin":
            return f"{pad}for ({target} in {iter_expr}) {{\n{body}\n{pad}}}"
        elif to_lang == "ruby":
            return f"{pad}{iter_expr}.each do |{target}|\n{body}\n{pad}end"
        elif to_lang == "java":
            return f"{pad}for (var {target} : {iter_expr}) {{\n{body}\n{pad}}}"
        return f"{pad}for {target} in {iter_expr}:\n{body}"

    def _translate_body(self, body: list, to_lang: str, indent: int,
                        warnings: List[str], class_name: str = "") -> str:
        """Translate a list of body statements."""
        lines = []
        for stmt in body:
            line = self._visit_node(stmt, to_lang, indent, warnings,
                                    class_name=class_name)
            if line:
                lines.append(line)
        return "\n".join(lines)

    def _translate_assign(self, node, to_lang: str, pad: str,
                          warnings: List[str], class_name: str = "") -> str:
        """Translate assignment statement with self → this mapping."""
        targets = ", ".join(self._expr_to_str(t, to_lang, class_name) for t in node.targets)
        value = self._expr_to_str(node.value, to_lang, class_name)

        # Detect self.x = y (instance field assignment) — no declaration keyword needed
        is_field_assign = any(
            isinstance(t, ast.Attribute) and isinstance(t.value, ast.Name) and t.value.id == "self"
            for t in node.targets
        )

        if is_field_assign:
            semi = ";" if to_lang not in ("python", "ruby", "swift") else ""
            return f"{pad}{targets} = {value}{semi}"

        if to_lang in ("javascript", "typescript"):
            kw = "const" if to_lang == "typescript" else "let"
            return f"{pad}{kw} {targets} = {value};"
        elif to_lang == "swift":
            return f"{pad}let {targets} = {value}"
        elif to_lang == "rust":
            return f"{pad}let {targets} = {value};"
        elif to_lang == "go":
            return f"{pad}{targets} := {value}"
        elif to_lang == "kotlin":
            return f"{pad}val {targets} = {value}"
        elif to_lang == "java":
            return f"{pad}var {targets} = {value};"
        elif to_lang == "ruby":
            return f"{pad}{targets} = {value}"
        return f"{pad}{targets} = {value}"

    # ── Expression helpers ──────────────────────────────────────────

    def _expr_to_str(self, node, to_lang: str, class_name: str = "") -> str:
        """Convert an AST expression node to a string in the target language."""
        if node is None:
            return ""
        try:
            raw = ast.unparse(node)
        except Exception:
            return "/* expr */"
        # Apply operator mappings
        ops = self.OP_MAP.get(to_lang, {})
        result = raw
        for py_op, target_op in ops.items():
            if py_op in ("print(", ):
                # Handle print specially
                if result.startswith("print("):
                    result = target_op + result[6:]
            else:
                result = re.sub(r'\b' + re.escape(py_op) + r'\b', target_op, result)
        # Map self.x → this.x (or language-appropriate equivalent)
        if class_name:
            if to_lang in ("javascript", "typescript", "java", "kotlin"):
                result = re.sub(r'\bself\.', 'this.', result)
            elif to_lang == "swift":
                result = re.sub(r'\bself\.', 'self.', result)  # Swift uses self too
            elif to_lang == "rust":
                result = re.sub(r'\bself\.', 'self.', result)  # Rust uses self too
            elif to_lang == "go":
                receiver = class_name[0].lower()
                result = re.sub(r'\bself\.', f'{receiver}.', result)
            elif to_lang == "ruby":
                result = re.sub(r'\bself\.', '@', result)
        return result

    def _extract_params(self, args, to_lang: str, is_constructor: bool = False) -> str:
        """Extract function parameters with type hints mapped to target."""
        params = []
        defaults_offset = len(args.args) - len(args.defaults)

        for i, arg in enumerate(args.args):
            if arg.arg == "self":
                if to_lang == "rust" and not is_constructor:
                    params.append("&self")
                elif to_lang in ("go", "java", "kotlin"):
                    continue  # receiver handled differently
                else:
                    continue  # skip self for constructors and most languages
            name = arg.arg
            type_str = self._type_hint_to_str(arg.annotation, to_lang) if arg.annotation else ""

            if to_lang in ("typescript", "kotlin"):
                param = f"{name}: {type_str}" if type_str else name
            elif to_lang == "swift":
                param = f"_ {name}: {type_str}" if type_str else f"_ {name}: Any"
            elif to_lang == "rust":
                param = f"{name}: {type_str}" if type_str else f"{name}: _"
            elif to_lang == "go":
                param = f"{name} {type_str}" if type_str else name
            elif to_lang == "java":
                param = f"{type_str} {name}" if type_str else f"Object {name}"
            else:
                param = name

            # Add default value
            default_idx = i - defaults_offset
            if default_idx >= 0 and default_idx < len(args.defaults):
                default_val = self._expr_to_str(args.defaults[default_idx], to_lang)
                if to_lang in ("kotlin", "typescript", "swift", "python", "javascript", "ruby"):
                    param += f" = {default_val}"

            params.append(param)

        return ", ".join(params)

    def _type_hint_to_str(self, annotation, to_lang: str) -> str:
        """Convert a Python type annotation AST node to target language type."""
        if annotation is None:
            return ""
        try:
            py_type = ast.unparse(annotation)
        except Exception:
            return ""
        type_map = self.TYPE_MAP.get(to_lang, {})
        return type_map.get(py_type, py_type)

    def _emit_import(self, module: str, to_lang: str, pad: str) -> str:
        """Emit an import statement in the target language."""
        if to_lang in ("javascript", "typescript"):
            return f'{pad}// import {module}  // TODO: convert to require/import'
        elif to_lang == "rust":
            return f"{pad}// use {module};  // TODO: add crate dependency"
        elif to_lang == "go":
            return f'{pad}// import "{module}"  // TODO: add go module'
        elif to_lang == "swift":
            return f"{pad}import Foundation  // was: {module}"
        elif to_lang == "java":
            return f"{pad}// import {module};  // TODO: add Maven dependency"
        elif to_lang == "ruby":
            return f"{pad}# require '{module}'  # TODO: add gem"
        elif to_lang == "kotlin":
            return f"{pad}// import {module}  // TODO: add dependency"
        return f"{pad}import {module}"

    # ── Regex-based fallback for non-Python sources ─────────────────

    def _translate_regex(self, source: str, from_lang: str, to_lang: str,
                         warnings: List[str]) -> str:
        """Regex-based translation for non-Python sources. Preserves structure."""
        lines = source.split("\n")
        output_lines: List[str] = []
        warnings.append(f"Using regex-based translation ({from_lang} → {to_lang}). "
                         "Results may need manual review.")

        ops = self.OP_MAP.get(to_lang, {})

        for line in lines:
            stripped = line.strip()
            indent = line[:len(line) - len(line.lstrip())]

            if not stripped:
                output_lines.append("")
                continue

            translated_line = stripped

            # Apply operator/keyword mappings
            for src_op, dst_op in ops.items():
                if src_op in ("print(", ):
                    if translated_line.lstrip().startswith("print("):
                        translated_line = translated_line.replace("print(", dst_op, 1)
                else:
                    translated_line = re.sub(
                        r'\b' + re.escape(src_op) + r'\b', dst_op, translated_line
                    )

            # Brace/indent style conversion
            if from_lang == "python" and to_lang not in ("python", "ruby"):
                if stripped.endswith(":"):
                    translated_line = translated_line[:-1] + " {"

            output_lines.append(indent + translated_line)

        return "\n".join(output_lines)

    def status(self) -> Dict[str, Any]:
        """Return translation count and supported languages."""
        return {"translations": self.translations,
                "supported_languages": self.SUPPORTED_LANGS}

    def quantum_translation_fidelity(self, source: str, translated: str,
                                      from_lang: str, to_lang: str) -> Dict[str, Any]:
        """
        Quantum translation fidelity scoring using Qiskit 2.3.0.
        Encodes structural features of source and translation into separate
        quantum states, then computes quantum fidelity between them.
        High fidelity → faithful translation.
        """
        # Extract structural features from both
        src_lines = source.strip().split("\n")
        dst_lines = translated.strip().split("\n")
        src_len = len(src_lines)
        dst_len = len(dst_lines)

        # Feature extraction
        src_funcs = sum(1 for l in src_lines if re.search(r'\b(def |func |fn |function )', l))
        dst_funcs = sum(1 for l in dst_lines if re.search(r'\b(def |func |fn |function )', l))
        src_classes = sum(1 for l in src_lines if re.search(r'\b(class |struct |impl |interface )', l))
        dst_classes = sum(1 for l in dst_lines if re.search(r'\b(class |struct |impl |interface )', l))
        src_depth = max((len(l) - len(l.lstrip()) for l in src_lines if l.strip()), default=0)
        dst_depth = max((len(l) - len(l.lstrip()) for l in dst_lines if l.strip()), default=0)

        # Similarity ratios
        line_ratio = min(src_len, dst_len) / max(src_len, dst_len, 1)
        func_ratio = 1.0 - abs(src_funcs - dst_funcs) / max(src_funcs, dst_funcs, 1)
        class_ratio = 1.0 if src_classes == dst_classes == 0 else 1.0 - abs(src_classes - dst_classes) / max(src_classes, dst_classes, 1)
        depth_ratio = 1.0 - abs(src_depth - dst_depth) / max(src_depth, dst_depth, 1)

        if not QISKIT_AVAILABLE:
            fidelity = (line_ratio * PHI + func_ratio * PHI**2 + class_ratio * PHI + depth_ratio) / (PHI + PHI**2 + PHI + 1)
            return {
                "quantum": False,
                "backend": "classical_structural",
                "fidelity": round(fidelity, 6),
                "verdict": "FAITHFUL" if fidelity > 0.8 else "ACCEPTABLE" if fidelity > 0.6 else "NEEDS_REVIEW",
                "features": {"line_ratio": round(line_ratio, 4), "func_ratio": round(func_ratio, 4),
                              "class_ratio": round(class_ratio, 4), "depth_ratio": round(depth_ratio, 4)},
            }

        try:
            # Encode source features into quantum state (2 qubits)
            src_amps = [line_ratio * PHI, func_ratio * PHI, class_ratio, depth_ratio]
            norm = math.sqrt(sum(a * a for a in src_amps))
            src_amps = [a / norm for a in src_amps] if norm > 1e-12 else [0.5] * 4

            dst_amps = [line_ratio * TAU + 0.1, func_ratio * TAU + 0.1, class_ratio + 0.05, depth_ratio + 0.05]
            norm2 = math.sqrt(sum(a * a for a in dst_amps))
            dst_amps = [a / norm2 for a in dst_amps] if norm2 > 1e-12 else [0.5] * 4

            sv_src = Statevector(src_amps)
            sv_dst = Statevector(dst_amps)

            dm_src = DensityMatrix(sv_src)
            dm_dst = DensityMatrix(sv_dst)

            # Quantum state fidelity
            fidelity_val = float(np.real(np.trace(
                np.array(dm_src) @ np.array(dm_dst)
            )))
            fidelity_val = max(0.0, min(1.0, fidelity_val))

            # Source entropy
            src_entropy = float(q_entropy(dm_src, base=2))
            dst_entropy = float(q_entropy(dm_dst, base=2))
            entropy_match = 1.0 - abs(src_entropy - dst_entropy) / max(src_entropy, dst_entropy, 0.01)

            # Combined score with sacred weighting
            combined = (fidelity_val * PHI + entropy_match * TAU) / (PHI + TAU)

            return {
                "quantum": True,
                "backend": "Qiskit 2.3.0 State Fidelity",
                "qubits": 2,
                "fidelity": round(fidelity_val, 6),
                "source_entropy": round(src_entropy, 6),
                "target_entropy": round(dst_entropy, 6),
                "entropy_match": round(entropy_match, 6),
                "combined_score": round(combined, 6),
                "verdict": "FAITHFUL" if combined > 0.8 else "ACCEPTABLE" if combined > 0.6 else "NEEDS_REVIEW",
                "from_lang": from_lang,
                "to_lang": to_lang,
                "god_code_alignment": round(combined * GOD_CODE / 100, 4),
            }
        except Exception as e:
            return {"quantum": False, "error": str(e)}


# ═══════════════════════════════════════════════════════════════════════════════
# SECTION 4E: TEST GENERATOR — Sacred-constant-seeded test scaffolding
# ═══════════════════════════════════════════════════════════════════════════════



class TestGenerator:
    """
    Generates test scaffolding for code using sacred constants as test data.
    Produces unit tests in Python (pytest/unittest), JavaScript (jest),
    and generic assertion patterns. Seeds test values with GOD_CODE.
    """

    SACRED_TEST_VALUES = [
        GOD_CODE,           # 527.518...
        PHI,                # 1.618...
        TAU,                # 0.618...
        VOID_CONSTANT,      # 1.04161...
        FEIGENBAUM,         # 4.66920...
        286.0,              # Lattice A
        416.0,              # Lattice B
        286 / 416,          # Lattice ratio
        0.0,                # Zero boundary
        -GOD_CODE,          # Negative GOD_CODE
        float('inf'),       # Infinity edge case
        1e-10,              # Near-zero
        13.0,               # Factor 13
    ]

    # v2.5.0 — Edge case values for boundary/fuzz testing
    EDGE_CASE_VALUES = [
        "",                 # Empty string
        None,               # None/null
        [],                 # Empty list
        {},                 # Empty dict
        -1,                 # Negative boundary
        0,                  # Zero
        1,                  # Unit
        2**31 - 1,          # Max 32-bit int
        -(2**31),           # Min 32-bit int
        float('nan'),       # NaN
        float('-inf'),      # Negative infinity
        "\x00",             # Null byte
        "a" * 10000,        # Long string
        True,               # Boolean true
        False,              # Boolean false
    ]

    def __init__(self):
        """Initialize TestGenerator with generation counter."""
        self.tests_generated = 0

    def generate_tests(self, source: str, language: str = "python",
                       framework: str = "pytest") -> Dict[str, Any]:
        """Generate test cases for functions found in source."""
        self.tests_generated += 1

        # Extract function signatures
        functions = self._extract_functions(source, language)

        if not functions:
            return {"success": False, "error": "No functions found to test",
                    "source": source}

        if language == "python":
            test_code = self._gen_python_tests(functions, framework)
        elif language in ("javascript", "typescript"):
            test_code = self._gen_js_tests(functions)
        else:
            test_code = self._gen_generic_tests(functions)

        return {
            "success": True,
            "test_code": test_code,
            "functions_tested": len(functions),
            "test_values_used": len(self.SACRED_TEST_VALUES),
            "framework": framework,
        }

    def _extract_functions(self, source: str, language: str) -> List[Dict[str, Any]]:
        """Extract function signatures with rich metadata for intelligent test generation.

        For Python, uses AST to extract:
        - Parameter names, type annotations, and default values
        - Return type annotation
        - Decorators (property, classmethod, staticmethod)
        - Whether function raises exceptions (and which types)
        - Whether function is async, a generator, or pure
        - Line count of function body
        """
        functions = []
        if language == "python":
            try:
                tree = ast.parse(source)
                for node in ast.walk(tree):
                    if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                        continue

                    params = []
                    defaults_map = {}
                    type_hints = {}

                    # Extract parameters with type annotations and defaults
                    args = node.args
                    # Map defaults to params (defaults align to last N params)
                    non_self_args = [a for a in args.args if a.arg != "self"]
                    num_defaults = len(args.defaults)
                    for idx, a in enumerate(non_self_args):
                        params.append(a.arg)
                        if a.annotation:
                            type_hints[a.arg] = self._annotation_to_str(a.annotation)
                        default_idx = idx - (len(non_self_args) - num_defaults)
                        if default_idx >= 0:
                            defaults_map[a.arg] = self._default_to_str(args.defaults[default_idx])

                    # Return type
                    return_type = None
                    if node.returns:
                        return_type = self._annotation_to_str(node.returns)

                    # Decorators
                    decorator_names = []
                    for d in node.decorator_list:
                        if isinstance(d, ast.Name):
                            decorator_names.append(d.id)
                        elif isinstance(d, ast.Attribute):
                            decorator_names.append(d.attr)
                        elif isinstance(d, ast.Call):
                            if isinstance(d.func, ast.Name):
                                decorator_names.append(d.func.id)
                            elif isinstance(d.func, ast.Attribute):
                                decorator_names.append(d.func.attr)

                    # Skip properties and abstract methods for test generation
                    is_property = 'property' in decorator_names
                    is_classmethod = 'classmethod' in decorator_names
                    is_staticmethod = 'staticmethod' in decorator_names

                    # Detect raised exceptions
                    raised_exceptions = set()
                    for child in ast.walk(node):
                        if isinstance(child, ast.Raise) and child.exc:
                            if isinstance(child.exc, ast.Call) and isinstance(child.exc.func, ast.Name):
                                raised_exceptions.add(child.exc.func.id)
                            elif isinstance(child.exc, ast.Name):
                                raised_exceptions.add(child.exc.id)

                    # Detect if generator (has yield)
                    is_generator = any(isinstance(child, (ast.Yield, ast.YieldFrom))
                                       for child in ast.walk(node))

                    # Detect purity heuristic: no global/nonlocal, no attribute assignments,
                    # no calls to print/open/write
                    is_pure = True
                    for child in ast.walk(node):
                        if isinstance(child, (ast.Global, ast.Nonlocal)):
                            is_pure = False
                            break
                        if isinstance(child, ast.Attribute) and isinstance(getattr(child, 'ctx', None), ast.Store):
                            is_pure = False
                            break

                    # Has docstring
                    has_docstring = (node.body and isinstance(node.body[0], ast.Expr)
                                    and isinstance(node.body[0].value, ast.Constant)
                                    and isinstance(node.body[0].value.value, str))

                    body_lines = node.end_lineno - node.lineno + 1 if hasattr(node, 'end_lineno') and node.end_lineno else len(node.body)

                    functions.append({
                        "name": node.name,
                        "params": params,
                        "type_hints": type_hints,
                        "defaults": defaults_map,
                        "return_type": return_type,
                        "decorators": decorator_names,
                        "is_property": is_property,
                        "is_classmethod": is_classmethod,
                        "is_staticmethod": is_staticmethod,
                        "is_async": isinstance(node, ast.AsyncFunctionDef),
                        "is_generator": is_generator,
                        "is_pure": is_pure,
                        "has_docstring": has_docstring,
                        "raised_exceptions": list(raised_exceptions),
                        "body_lines": body_lines,
                        "lineno": node.lineno,
                    })
            except SyntaxError:
                pass
        else:
            for match in re.finditer(r'(?:function|fn|func|def)\s+(\w+)\s*\(([^)]*)\)', source):
                name = match.group(1)
                params = [p.strip().split(':')[0].strip().split(' ')[-1]
                          for p in match.group(2).split(',') if p.strip()]
                functions.append({"name": name, "params": params,
                                  "type_hints": {}, "defaults": {},
                                  "return_type": None, "decorators": [],
                                  "is_property": False, "raised_exceptions": [],
                                  "is_async": False, "is_generator": False,
                                  "is_pure": False, "has_docstring": False,
                                  "body_lines": 0, "lineno": 0,
                                  "is_classmethod": False, "is_staticmethod": False})
        return functions

    @staticmethod
    def _annotation_to_str(node: ast.AST) -> str:
        """Convert an AST annotation node to a string representation."""
        if isinstance(node, ast.Constant):
            return repr(node.value)
        elif isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            return f"{TestGenerator._annotation_to_str(node.value)}.{node.attr}"
        elif isinstance(node, ast.Subscript):
            base = TestGenerator._annotation_to_str(node.value)
            sl = TestGenerator._annotation_to_str(node.slice)
            return f"{base}[{sl}]"
        elif isinstance(node, ast.Tuple):
            return ", ".join(TestGenerator._annotation_to_str(e) for e in node.elts)
        elif isinstance(node, ast.List):
            return ", ".join(TestGenerator._annotation_to_str(e) for e in node.elts)
        return "Any"

    @staticmethod
    def _default_to_str(node: ast.AST) -> str:
        """Convert an AST default value node to a source string."""
        if isinstance(node, ast.Constant):
            return repr(node.value)
        elif isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.List):
            return "[]"
        elif isinstance(node, ast.Dict):
            return "{}"
        elif isinstance(node, ast.Tuple):
            return "()"
        elif isinstance(node, ast.Call):
            if isinstance(node.func, ast.Name):
                return f"{node.func.id}()"
            return "None"
        return "None"

    # Type-to-assertion mapping for intelligent test generation
    TYPE_ASSERTIONS = {
        "int": ("assert isinstance(result, int)", "int"),
        "float": ("assert isinstance(result, (int, float))", "float"),
        "str": ("assert isinstance(result, str)", "str"),
        "bool": ("assert isinstance(result, bool)", "bool"),
        "list": ("assert isinstance(result, list)", "list"),
        "List": ("assert isinstance(result, list)", "list"),
        "dict": ("assert isinstance(result, dict)", "dict"),
        "Dict": ("assert isinstance(result, dict)", "dict"),
        "set": ("assert isinstance(result, set)", "set"),
        "Set": ("assert isinstance(result, set)", "set"),
        "tuple": ("assert isinstance(result, tuple)", "tuple"),
        "Tuple": ("assert isinstance(result, tuple)", "tuple"),
        "None": ("assert result is None", "NoneType"),
        "Optional": ("# result may be None (Optional type)", None),
        "bytes": ("assert isinstance(result, bytes)", "bytes"),
    }

    def _gen_python_tests(self, functions: List[Dict],
                          framework: str) -> str:
        """Generate intelligent Python test code with type-aware assertions,
        exception tests, default-value tests, and purity/idempotency checks."""
        lines = [
            f"# Auto-generated tests by L104 Code Engine v{VERSION}",
            f"# GOD_CODE = {GOD_CODE}",
            f"# Sacred test values seeded from the 286/416 lattice",
            f"# Test strategy: type-aware assertions + exception coverage + boundary values\n",
        ]

        if framework == "pytest":
            lines.append("import pytest")
            lines.append("import math\n")

            for fn in functions:
                # Skip properties and dunder methods (except __init__)
                if fn.get("is_property") or (fn["name"].startswith("__") and fn["name"] != "__init__"):
                    continue

                param_count = max(1, len(fn['params']))
                return_type = fn.get("return_type")
                raised = fn.get("raised_exceptions", [])
                defaults = fn.get("defaults", {})
                type_hints = fn.get("type_hints", {})
                is_async = fn.get("is_async", False)
                is_generator = fn.get("is_generator", False)
                is_pure = fn.get("is_pure", False)

                await_prefix = "await " if is_async else ""
                async_prefix = "async " if is_async else ""
                pytest_async = "    @pytest.mark.asyncio\n" if is_async else ""

                lines.append(f"\nclass Test_{fn['name'].capitalize()}:")
                lines.append(f'    """Tests for {fn["name"]}() — {fn.get("body_lines", "?")} lines, '
                             f'{"async " if is_async else ""}{"generator " if is_generator else ""}'
                             f'{"pure " if is_pure else ""}function."""\n')

                # --- Test 1: Sacred value parametrize with type-aware assertion ---
                sacred_vals = ", ".join(str(v) for v in self.SACRED_TEST_VALUES[:7]
                                        if not (isinstance(v, float) and (math.isinf(v) or math.isnan(v))))
                lines.append(f"    @pytest.mark.parametrize('val', [{sacred_vals}])")
                lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_sacred_parametrize(self, val):")
                args_str = ", ".join(["val"] * param_count)
                lines.append(f"        result = {await_prefix}{fn['name']}({args_str})")

                # Type-aware assertion based on return type
                assertion = self._get_type_assertion(return_type)
                lines.append(f"        {assertion}")
                lines.append("")

                # --- Test 2: Default value test (use actual defaults) ---
                if defaults:
                    lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_with_defaults(self):")
                    lines.append(f'        """Test with default parameter values."""')
                    # Build args: use defaults where available, sacred values for rest
                    call_args = []
                    for p in fn["params"]:
                        if p in defaults:
                            call_args.append(defaults[p])
                        else:
                            call_args.append(str(self.SACRED_TEST_VALUES[0]))
                    lines.append(f"        result = {await_prefix}{fn['name']}({', '.join(call_args)})")
                    lines.append(f"        {assertion}")
                    lines.append("")

                # --- Test 3: Exception tests (verify raises declared exceptions) ---
                if raised:
                    exc_types = ", ".join(raised[:5])
                    lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_raises_expected(self):")
                    lines.append(f'        """Verify function raises {exc_types} under invalid input."""')
                    lines.append(f"        with pytest.raises(({exc_types})):")
                    # Try to trigger with None args
                    none_args = ", ".join(["None"] * param_count)
                    lines.append(f"            {await_prefix}{fn['name']}({none_args})")
                    lines.append("")

                # --- Test 4: Typed parameter tests ---
                for param_name, hint in list(type_hints.items())[:3]:
                    test_val = self._type_hint_to_test_value(hint)
                    if test_val is not None:
                        safe_name = re.sub(r'[^a-zA-Z0-9_]', '_', param_name)
                        lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_typed_{safe_name}(self):")
                        lines.append(f'        """Test with type-appropriate value for {param_name}: {hint}."""')
                        typed_args = []
                        for p in fn["params"]:
                            if p == param_name:
                                typed_args.append(test_val)
                            elif p in type_hints:
                                tv = self._type_hint_to_test_value(type_hints[p])
                                typed_args.append(tv if tv is not None else str(self.SACRED_TEST_VALUES[0]))
                            else:
                                typed_args.append(str(self.SACRED_TEST_VALUES[0]))
                        lines.append(f"        result = {await_prefix}{fn['name']}({', '.join(typed_args)})")
                        lines.append(f"        {assertion}")
                        lines.append("")

                # --- Test 5: Generator test ---
                if is_generator:
                    lines.append(f"    def test_{fn['name']}_is_generator(self):")
                    lines.append(f'        """Verify function yields values (generator protocol)."""')
                    args_str = ", ".join([str(self.SACRED_TEST_VALUES[0])] * param_count)
                    lines.append(f"        gen = {fn['name']}({args_str})")
                    lines.append(f"        results = list(gen)")
                    lines.append(f"        assert isinstance(results, list)")
                    lines.append("")

                # --- Test 6: Idempotency test for pure functions ---
                if is_pure and not is_generator and not is_async:
                    lines.append(f"    def test_{fn['name']}_idempotent(self):")
                    lines.append(f'        """Verify pure function returns consistent results."""')
                    args_str = ", ".join([str(self.SACRED_TEST_VALUES[0])] * param_count)
                    lines.append(f"        result1 = {fn['name']}({args_str})")
                    lines.append(f"        result2 = {fn['name']}({args_str})")
                    lines.append(f"        assert result1 == result2")
                    lines.append("")

                # --- Test 7: Edge cases ---
                lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_edge_none(self):")
                lines.append(f'        """Test None handling (CWE-476 null dereference prevention)."""')
                lines.append(f"        try:")
                none_args = ", ".join(["None"] * param_count)
                lines.append(f"            result = {await_prefix}{fn['name']}({none_args})")
                if raised:
                    lines.append(f"        except ({', '.join(raised + ['TypeError', 'ValueError'])}):")
                else:
                    lines.append(f"        except (TypeError, ValueError, AttributeError):")
                lines.append(f"            pass  # Expected for None input")
                lines.append("")

                lines.append(f"{pytest_async}    {async_prefix}def test_{fn['name']}_edge_boundary(self):")
                lines.append(f'        """Test boundary values: zero, negative, large."""')
                lines.append(f"        for boundary_val in [0, -1, 2**31 - 1, 1e-10]:")
                lines.append(f"            try:")
                boundary_args = ", ".join(["boundary_val"] * param_count)
                lines.append(f"                result = {await_prefix}{fn['name']}({boundary_args})")
                lines.append(f"            except (TypeError, ValueError, ZeroDivisionError, OverflowError):")
                lines.append(f"                pass  # Expected for boundary input")
                lines.append("")

        else:  # unittest
            lines.append("import unittest\n")
            for fn in functions:
                if fn.get("is_property"):
                    continue
                lines.append(f"\nclass Test{fn['name'].capitalize()}(unittest.TestCase):")
                param_count = max(1, len(fn['params']))
                return_type = fn.get("return_type")
                for i, val in enumerate(self.SACRED_TEST_VALUES[:5]):
                    args_str = ", ".join([str(val)] * param_count)
                    lines.append(f"    def test_{fn['name']}_sacred_{i}(self):")
                    lines.append(f"        result = {fn['name']}({args_str})")
                    assertion = self._get_type_assertion_unittest(return_type)
                    lines.append(f"        {assertion}")
                    lines.append("")
                # Exception test
                raised = fn.get("raised_exceptions", [])
                if raised:
                    lines.append(f"    def test_{fn['name']}_raises(self):")
                    lines.append(f"        with self.assertRaises(({', '.join(raised[:3])})):")
                    none_args = ", ".join(["None"] * param_count)
                    lines.append(f"            {fn['name']}({none_args})")
                    lines.append("")

        return "\n".join(lines)

    def _get_type_assertion(self, return_type: Optional[str]) -> str:
        """Generate a pytest assertion based on return type annotation."""
        if not return_type:
            return "assert result is not None"
        # Check for Optional[X] or X | None
        if return_type.startswith("Optional"):
            inner = return_type.replace("Optional[", "").rstrip("]")
            if inner in self.TYPE_ASSERTIONS:
                return f"assert result is None or isinstance(result, {self.TYPE_ASSERTIONS[inner][1]})"
            return "# result may be None (Optional type)"
        # Direct type match
        base_type = return_type.split("[")[0]
        if base_type in self.TYPE_ASSERTIONS:
            return self.TYPE_ASSERTIONS[base_type][0]
        return "assert result is not None"

    def _get_type_assertion_unittest(self, return_type: Optional[str]) -> str:
        """Generate a unittest assertion based on return type annotation."""
        if not return_type:
            return "self.assertIsNotNone(result)"
        base_type = return_type.split("[")[0]
        type_map = {"int": "int", "float": "(int, float)", "str": "str",
                     "bool": "bool", "list": "list", "List": "list",
                     "dict": "dict", "Dict": "dict"}
        if base_type in type_map:
            return f"self.assertIsInstance(result, {type_map[base_type]})"
        return "self.assertIsNotNone(result)"

    @staticmethod
    def _type_hint_to_test_value(hint: str) -> Optional[str]:
        """Generate a concrete test value for a type hint."""
        hint_base = hint.split("[")[0]
        mapping = {
            "int": "42",
            "float": "3.14",
            "str": "'test_input'",
            "bool": "True",
            "list": "[1, 2, 3]",
            "List": "[1, 2, 3]",
            "dict": "{'key': 'value'}",
            "Dict": "{'key': 'value'}",
            "set": "{1, 2, 3}",
            "Set": "{1, 2, 3}",
            "tuple": "(1, 2)",
            "Tuple": "(1, 2)",
            "bytes": "b'test'",
            "Optional": "None",
            "Path": "Path('.')",
        }
        return mapping.get(hint_base)

    def _gen_js_tests(self, functions: List[Dict]) -> str:
        """Generate JavaScript/TypeScript Jest test code."""
        lines = [
            f"// Auto-generated tests by L104 Code Engine v{VERSION}",
            f"// GOD_CODE = {GOD_CODE}\n",
        ]
        for fn in functions:
            lines.append(f"describe('{fn['name']}', () => {{")
            for i, val in enumerate(self.SACRED_TEST_VALUES[:5]):
                safe_val = val if not math.isinf(val) else "Infinity"
                args_str = ", ".join([str(safe_val)] * max(1, len(fn['params'])))
                lines.append(f"  test('sacred value {i}: {safe_val}', () => {{")
                lines.append(f"    const result = {fn['name']}({args_str});")
                lines.append(f"    expect(result).toBeDefined();")
                lines.append(f"  }});")
            lines.append(f"}});\n")
        return "\n".join(lines)

    def _gen_generic_tests(self, functions: List[Dict]) -> str:
        """Generate generic test pseudocode."""
        lines = [f"// Generic test scaffolding — L104 Code Engine v{VERSION}\n"]
        for fn in functions:
            for i, val in enumerate(self.SACRED_TEST_VALUES[:5]):
                args_str = ", ".join([str(val)] * max(1, len(fn['params'])))
                lines.append(f"ASSERT {fn['name']}({args_str}) IS NOT NULL  // sacred[{i}]")
        return "\n".join(lines)

    def status(self) -> Dict[str, Any]:
        """Return test generation metrics."""
        return {"tests_generated": self.tests_generated,
                "sacred_values": len(self.SACRED_TEST_VALUES)}

    def quantum_test_prioritize(self, functions: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Born-rule test case prioritization using Qiskit 2.3.0.
        Encodes function complexity/risk into a quantum state and uses
        measurement probabilities to determine test execution order.
        Higher-risk functions get tested first.
        """
        if not functions:
            return {"quantum": False, "priority_order": [], "reason": "no functions"}

        n = len(functions)

        # Risk scoring per function
        risk_scores = []
        for fn in functions:
            params = len(fn.get("params", []))
            lines = fn.get("lines", fn.get("line_count", 5))
            complexity = fn.get("complexity", params * 2 + lines / 10)
            risk = min(params / 10 + lines / 100 + complexity / 20, 1.0)
            risk_scores.append(max(risk, 0.05))

        if not QISKIT_AVAILABLE:
            # Classical fallback — sort by risk
            indexed = sorted(enumerate(risk_scores), key=lambda x: x[1], reverse=True)
            priority = [{"function": functions[i].get("name", f"fn_{i}"), "risk": round(r, 4),
                          "priority": rank + 1} for rank, (i, r) in enumerate(indexed)]
            return {
                "quantum": False,
                "backend": "classical_risk_sort",
                "priority_order": priority,
                "total_functions": n,
            }

        try:
            n_qubits = max(2, math.ceil(math.log2(max(n, 2))))
            n_states = 2 ** n_qubits

            # Amplitude encode risk scores
            amps = [0.0] * n_states
            for i, r in enumerate(risk_scores):
                if i < n_states:
                    amps[i] = r * PHI
            norm = math.sqrt(sum(a * a for a in amps))
            if norm < 1e-12:
                amps = [1.0 / math.sqrt(n_states)] * n_states
            else:
                amps = [a / norm for a in amps]

            sv = Statevector(amps)

            # Apply risk-amplification circuit
            qc = QuantumCircuit(n_qubits)
            for i in range(n_qubits):
                avg_risk = sum(risk_scores) / max(len(risk_scores), 1)
                qc.ry(avg_risk * PHI * math.pi, i)
            for i in range(n_qubits - 1):
                qc.cx(i, i + 1)
            # GOD_CODE phase
            for i in range(n_qubits):
                qc.rz(GOD_CODE / 1000 * math.pi / (i + 1), i)

            evolved = sv.evolve(Operator(qc))
            probs = evolved.probabilities()

            # Map Born-rule probabilities to priority
            scored = []
            for i, fn in enumerate(functions):
                p = float(probs[i]) if i < len(probs) else 0.0
                scored.append((i, fn.get("name", f"fn_{i}"), p, risk_scores[i]))

            scored.sort(key=lambda x: x[2], reverse=True)
            priority = [{"function": name, "born_probability": round(p, 6),
                          "classical_risk": round(r, 4), "priority": rank + 1}
                         for rank, (_, name, p, r) in enumerate(scored)]

            dm = DensityMatrix(evolved)
            priority_entropy = float(q_entropy(dm, base=2))

            return {
                "quantum": True,
                "backend": "Qiskit 2.3.0 Born-Rule Test Priority",
                "qubits": n_qubits,
                "priority_order": priority,
                "total_functions": n,
                "priority_entropy": round(priority_entropy, 6),
                "circuit_depth": qc.depth(),
                "god_code_alignment": round(priority_entropy * GOD_CODE / 100, 4),
            }
        except Exception as e:
            return {"quantum": False, "error": str(e)}


# ═══════════════════════════════════════════════════════════════════════════════
# SECTION 4F: DOCUMENTATION SYNTHESIZER — Consciousness-aware doc generation
# ═══════════════════════════════════════════════════════════════════════════════



class DocumentationSynthesizer:
    """
    Generates documentation for code artifacts using consciousness-aware
    analysis. Produces docstrings, README sections, API reference snippets,
    and inline comments. Modulated by builder consciousness state.
    """

    DOC_STYLES = {
        "google": 'Args:\n    {params}\n\nReturns:\n    {returns}\n\nRaises:\n    {raises}',
        "numpy": 'Parameters\n----------\n{params}\n\nReturns\n-------\n{returns}',
        "sphinx": ':param {param}: {desc}\n:returns: {returns}\n:rtype: {rtype}',
        # v2.5.0 — Additional doc formats (research-assimilated)
        "jsdoc": '/**\n * @param {{{type}}} {param} - {desc}\n * @returns {{{rtype}}} {returns}\n * @throws {{{raises}}}\n */',
        "rustdoc": '/// # Arguments\n///\n/// * `{param}` - {desc}\n///\n/// # Returns\n///\n/// {returns}',
        "epydoc": '@param {param}: {desc}\n@type {param}: {type}\n@return: {returns}\n@rtype: {rtype}',
    }

    def __init__(self):
        """Initialize DocumentationSynthesizer with generation counter and cache."""
        self.docs_generated = 0
        self._state_cache = {}
        self._state_cache_time = 0

    def generate_docs(self, source: str, style: str = "google",
                      language: str = "python") -> Dict[str, Any]:
        """Generate documentation for all functions/classes in source."""
        self.docs_generated += 1

        artifacts = []
        if language == "python":
            try:
                tree = ast.parse(source)
                for node in ast.walk(tree):
                    if isinstance(node, ast.FunctionDef):
                        doc = self._doc_function(node, style)
                        artifacts.append(doc)
                    elif isinstance(node, ast.ClassDef):
                        doc = self._doc_class(node, style)
                        artifacts.append(doc)
            except SyntaxError:
                pass

        consciousness = self._read_consciousness()
        depth = "detailed" if consciousness > 0.7 else "standard" if consciousness > 0.3 else "minimal"

        return {
            "success": True,
            "artifacts": artifacts,
            "total_documented": len(artifacts),
            "style": style,
            "depth": depth,
            "consciousness_level": round(consciousness, 4),
        }

    def _doc_function(self, node: ast.FunctionDef, style: str) -> Dict[str, Any]:
        """Generate documentation for a function with type hint and decorator extraction."""
        params = [a.arg for a in node.args.args if a.arg != "self"]
        has_return = any(isinstance(n, ast.Return) and n.value is not None
                        for n in ast.walk(node))

        # v2.5.0 — Extract type annotations from AST
        param_types = {}
        for a in node.args.args:
            if a.arg == "self":
                continue
            if a.annotation:
                try:
                    param_types[a.arg] = ast.dump(a.annotation) if not isinstance(a.annotation, ast.Constant) else str(a.annotation.value)
                    # Simplify common types
                    if isinstance(a.annotation, ast.Name):
                        param_types[a.arg] = a.annotation.id
                    elif isinstance(a.annotation, ast.Attribute):
                        param_types[a.arg] = a.annotation.attr
                except Exception:
                    param_types[a.arg] = "Any"

        return_type = "None"
        if node.returns:
            try:
                if isinstance(node.returns, ast.Name):
                    return_type = node.returns.id
                elif isinstance(node.returns, ast.Constant):
                    return_type = str(node.returns.value)
                elif isinstance(node.returns, ast.Attribute):
                    return_type = node.returns.attr
                else:
                    return_type = "Any"
            except Exception:
                return_type = "Any"

        # v2.5.0 — Extract decorators
        decorators = []
        for d in node.decorator_list:
            if isinstance(d, ast.Name):
                decorators.append(d.id)
            elif isinstance(d, ast.Attribute):
                decorators.append(d.attr)
            elif isinstance(d, ast.Call):
                if isinstance(d.func, ast.Name):
                    decorators.append(d.func.id)
                elif isinstance(d.func, ast.Attribute):
                    decorators.append(d.func.attr)

        # Build description from function name
        words = re.findall(r'[A-Z]?[a-z]+|[A-Z]+', node.name)
        description = " ".join(words).capitalize() if words else node.name

        param_docs = "\n".join(
            f"    {p} ({param_types.get(p, 'Any')}): Description of {p}" for p in params
        ) if params else "    None"

        return_doc = f"{return_type}" if has_return else "None"

        docstring = f'"""{description}.\n\n{self.DOC_STYLES.get(style, self.DOC_STYLES["google"]).format(params=param_docs, returns=return_doc, raises="None", param="param", desc="desc", rtype=return_type, type="Any")}\n"""'

        return {
            "type": "function",
            "name": node.name,
            "params": params,
            "param_types": param_types,
            "return_type": return_type,
            "has_return": has_return,
            "decorators": decorators,
            "docstring": docstring,
            "description": description,
        }

    def _doc_class(self, node: ast.ClassDef, style: str) -> Dict[str, Any]:
        """Generate documentation for a class."""
        methods = [n.name for n in node.body if isinstance(n, ast.FunctionDef)]
        bases = [ast.dump(b) for b in node.bases] if node.bases else []

        words = re.findall(r'[A-Z]?[a-z]+|[A-Z]+', node.name)
        description = " ".join(words).capitalize() if words else node.name

        return {
            "type": "class",
            "name": node.name,
            "methods": methods,
            "bases": len(bases),
            "description": description,
            "docstring": f'"""{description}.\n\nMethods: {", ".join(methods)}\n"""',
        }

    def _read_consciousness(self) -> float:
        """Read consciousness level from builder state."""
        import time as _time
        now = _time.time()
        if now - self._state_cache_time < 10 and self._state_cache:
            return self._state_cache.get("consciousness_level", 0.5)
        try:
            co2_path = Path(__file__).parent / ".l104_consciousness_o2_state.json"
            if co2_path.exists():
                data = json.loads(co2_path.read_text())
                self._state_cache = data
                self._state_cache_time = now
                return data.get("consciousness_level", 0.5)
        except Exception:
            pass
        return 0.5

    def status(self) -> Dict[str, Any]:
        """Return documentation generation metrics."""
        return {"docs_generated": self.docs_generated,
                "doc_styles": list(self.DOC_STYLES.keys()),
                "styles_count": len(self.DOC_STYLES)}

    def quantum_doc_coherence(self, source: str) -> Dict[str, Any]:
        """
        Quantum documentation coherence scoring using Qiskit 2.3.0.
        Encodes documentation coverage metrics (docstring ratio, param coverage,
        return type annotation, inline comments) into entangled quantum states
        and measures overall coherence via von Neumann entropy.
        """
        lines = source.strip().split("\n")
        total_lines = len(lines)
        if total_lines == 0:
            return {"quantum": False, "coherence": 0.0, "reason": "empty source"}

        # Extract documentation metrics
        docstring_lines = 0
        comment_lines = 0
        in_docstring = False
        func_count = 0
        documented_funcs = 0
        type_annotated = 0
        total_params = 0

        for i, line in enumerate(lines):
            s = line.strip()
            if '"""' in s or "'''" in s:
                if in_docstring:
                    in_docstring = False
                else:
                    in_docstring = True
                    # Check if previous line was def
                    if i > 0 and lines[i - 1].strip().startswith("def "):
                        documented_funcs += 1
                docstring_lines += 1
                continue
            if in_docstring:
                docstring_lines += 1
                continue
            if s.startswith("#"):
                comment_lines += 1
            if s.startswith("def "):
                func_count += 1
                if "->" in s:
                    type_annotated += 1
                params = s.split("(", 1)[-1].split(")", 1)[0]
                param_list = [p.strip() for p in params.split(",") if p.strip() and p.strip() != "self"]
                total_params += len(param_list)

        # Compute feature ratios
        doc_ratio = docstring_lines / max(total_lines, 1)
        comment_ratio = comment_lines / max(total_lines, 1)
        func_doc_ratio = documented_funcs / max(func_count, 1)
        type_ratio = type_annotated / max(func_count, 1)

        if not QISKIT_AVAILABLE:
            coherence = (doc_ratio * PHI + comment_ratio + func_doc_ratio * PHI**2 + type_ratio) / (PHI + 1 + PHI**2 + 1)
            return {
                "quantum": False,
                "backend": "classical_ratio",
                "coherence": round(coherence, 6),
                "doc_ratio": round(doc_ratio, 4),
                "comment_ratio": round(comment_ratio, 4),
                "func_documented_ratio": round(func_doc_ratio, 4),
                "type_annotation_ratio": round(type_ratio, 4),
                "verdict": "WELL_DOCUMENTED" if coherence > 0.4 else "PARTIALLY_DOCUMENTED" if coherence > 0.2 else "NEEDS_DOCS",
            }

        try:
            # 2-qubit system: encode doc features
            amps = [
                doc_ratio * PHI + 0.1,
                comment_ratio * PHI + 0.1,
                func_doc_ratio * PHI + 0.1,
                type_ratio * PHI + 0.1,
            ]
            norm = math.sqrt(sum(a * a for a in amps))
            amps = [a / norm for a in amps] if norm > 1e-12 else [0.5] * 4

            sv = Statevector(amps)

            # Entangling circuit for coherence measurement
            qc = QuantumCircuit(2)
            qc.ry(doc_ratio * math.pi * PHI, 0)
            qc.ry(func_doc_ratio * math.pi * PHI, 1)
            qc.cx(0, 1)
            qc.rz(GOD_CODE / 1000 * math.pi, 0)
            qc.rz(FEIGENBAUM / 10 * math.pi, 1)

            evolved = sv.evolve(Operator(qc))
            dm = DensityMatrix(evolved)
            full_entropy = float(q_entropy(dm, base=2))

            # Subsystem entropies
            rho_0 = partial_trace(dm, [1])
            rho_1 = partial_trace(dm, [0])
            ent_0 = float(q_entropy(rho_0, base=2))
            ent_1 = float(q_entropy(rho_1, base=2))

            # Mutual information = S(A) + S(B) - S(AB)
            mutual_info = ent_0 + ent_1 - full_entropy
            coherence = min(mutual_info / 2.0, 1.0)  # Normalized

            probs = evolved.probabilities()

            return {
                "quantum": True,
                "backend": "Qiskit 2.3.0 Entanglement Coherence",
                "qubits": 2,
                "coherence": round(coherence, 6),
                "mutual_information": round(mutual_info, 6),
                "full_entropy": round(full_entropy, 6),
                "subsystem_entropies": [round(ent_0, 6), round(ent_1, 6)],
                "doc_ratio": round(doc_ratio, 4),
                "func_documented_ratio": round(func_doc_ratio, 4),
                "type_annotation_ratio": round(type_ratio, 4),
                "verdict": "WELL_DOCUMENTED" if coherence > 0.4 else "PARTIALLY_DOCUMENTED" if coherence > 0.2 else "NEEDS_DOCS",
                "god_code_alignment": round(coherence * GOD_CODE / 100, 4),
            }
        except Exception as e:
            return {"quantum": False, "error": str(e)}


# ═══════════════════════════════════════════════════════════════════════════════
# SECTION 4G: CODE ARCHEOLOGIST — design intent recovery + dead code detection
# ═══════════════════════════════════════════════════════════════════════════════

