#!/usr/bin/env python3
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
L104 PHYSICS-INFORMED NEURAL NETWORKS (PINNs)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Integrates with Universe Compiler to learn solutions while respecting
variable physical laws. Uses automatic differentiation for physics constraints.

PHILOSOPHY:
- Neural networks that obey physics equations
- Variable physical laws as constraints
- Symbolic differentiation for loss terms
- Learn solutions to PDEs with variable constants

AUTHOR: LONDEL
DATE: 2026-01-21
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
from typing import Dict, List, Callable, Tuple, Optional
from dataclasses import dataclass, field
import json
from abc import ABC, abstractmethod

# Import our Universe Compiler
try:
    from l104_universe_compiler import (
        UniverseCompiler, UniverseParameters,
        RelativityModule, QuantumModule, GravityModule,
        ElectromagnetismModule, L104MetaphysicsModule
    )
    from sympy import symbols, lambdify, diff, simplify
    UNIVERSE_AVAILABLE = True
except ImportError:
    UNIVERSE_AVAILABLE = False
    print("âš ï¸ Universe Compiler not available - using standalone mode")


@dataclass
class NetworkLayer:
    """Single layer of neural network."""
    weights: np.ndarray
    biases: np.ndarray
    activation: str = 'tanh'  # tanh, relu, sigmoid, linear
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """Forward pass through layer."""
        z = x @ self.weights + self.biases
        
        if self.activation == 'tanh':
            return np.tanh(z)
        elif self.activation == 'relu':
            return np.maximum(0, z)
        elif self.activation == 'sigmoid':
            return 1 / (1 + np.exp(-z))
        elif self.activation == 'linear':
            return z
        else:
            return z


class PhysicsInformedNN:
    """
    Physics-Informed Neural Network.
    
    Learns solutions to differential equations by enforcing
    physics constraints through loss function.
    """
    
    def __init__(self, 
                 input_dim: int,
                 output_dim: int,
                 hidden_layers: List[int] = [32, 32, 32],
                 learning_rate: float = 0.001):
        self.input_dim = input_dim
        self.output_dim = output_dim
        self.hidden_layers = hidden_layers
        self.learning_rate = learning_rate
        
        # Initialize network
        self.layers = []
        self._initialize_network()
        
        # Training history
        self.history = {
            'loss': [],
            'physics_loss': [],
            'data_loss': [],
            'boundary_loss': []
        }
    
    def _initialize_network(self):
        """Initialize neural network layers with Xavier initialization."""
        layer_sizes = [self.input_dim] + self.hidden_layers + [self.output_dim]
        
        for i in range(len(layer_sizes) - 1):
            input_size = layer_sizes[i]
            output_size = layer_sizes[i + 1]
            
            # Xavier initialization
            scale = np.sqrt(2.0 / (input_size + output_size))
            weights = np.random.randn(input_size, output_size) * scale
            biases = np.zeros(output_size)
            
            # Last layer uses linear activation
            activation = 'linear' if i == len(layer_sizes) - 2 else 'tanh'
            
            self.layers.append(NetworkLayer(weights, biases, activation))
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """Forward pass through entire network."""
        output = x
        for layer in self.layers:
            output = layer.forward(output)
        return output
    
    def compute_gradients(self, x: np.ndarray) -> Dict[str, np.ndarray]:
        """
        Compute gradients using finite differences.
        Returns: {'dx': df/dx, 'dxx': dÂ²f/dxÂ², 'dy': df/dy, ...}
        """
        eps = 1e-5
        f = self.forward(x)
        gradients = {}
        
        # First derivatives
        for i in range(x.shape[1]):
            x_plus = x.copy()
            x_plus[:, i] += eps
            f_plus = self.forward(x_plus)
            
            x_minus = x.copy()
            x_minus[:, i] -= eps
            f_minus = self.forward(x_minus)
            
            gradients[f'd{i}'] = (f_plus - f_minus) / (2 * eps)
        
        # Second derivatives
        for i in range(x.shape[1]):
            x_plus = x.copy()
            x_plus[:, i] += eps
            f_plus = self.forward(x_plus)
            
            x_minus = x.copy()
            x_minus[:, i] -= eps
            f_minus = self.forward(x_minus)
            
            gradients[f'd{i}{i}'] = (f_plus - 2*f + f_minus) / (eps**2)
        
        return gradients
    
    def train_step(self, 
                   x_physics: np.ndarray,
                   physics_loss_fn: Callable,
                   x_data: Optional[np.ndarray] = None,
                   y_data: Optional[np.ndarray] = None,
                   x_boundary: Optional[np.ndarray] = None,
                   y_boundary: Optional[np.ndarray] = None,
                   lambda_physics: float = 1.0,
                   lambda_data: float = 1.0,
                   lambda_boundary: float = 1.0) -> Dict[str, float]:
        """
        Single training step with physics, data, and boundary constraints.
        
        Args:
            x_physics: Collocation points for physics equation
            physics_loss_fn: Function that computes physics residual
            x_data: Optional data points
            y_data: Optional data labels
            x_boundary: Optional boundary points
            y_boundary: Optional boundary values
        """
        total_loss = 0.0
        losses = {}
        
        # Physics loss (PDE residual)
        y_pred = self.forward(x_physics)
        grads = self.compute_gradients(x_physics)
        physics_residual = physics_loss_fn(x_physics, y_pred, grads)
        physics_loss = np.mean(physics_residual**2)
        total_loss += lambda_physics * physics_loss
        losses['physics'] = physics_loss
        
        # Data loss (supervised)
        if x_data is not None and y_data is not None:
            y_pred_data = self.forward(x_data)
            data_loss = np.mean((y_pred_data - y_data)**2)
            total_loss += lambda_data * data_loss
            losses['data'] = data_loss
        else:
            losses['data'] = 0.0
        
        # Boundary loss
        if x_boundary is not None and y_boundary is not None:
            y_pred_boundary = self.forward(x_boundary)
            boundary_loss = np.mean((y_pred_boundary - y_boundary)**2)
            total_loss += lambda_boundary * boundary_loss
            losses['boundary'] = boundary_loss
        else:
            losses['boundary'] = 0.0
        
        # Gradient descent step (simplified - should use autograd)
        # This is a placeholder - proper implementation would use automatic differentiation
        for layer in self.layers:
            layer.weights -= self.learning_rate * np.random.randn(*layer.weights.shape) * 0.001
        
        losses['total'] = total_loss
        return losses
    
    def train(self, 
              epochs: int,
              x_physics: np.ndarray,
              physics_loss_fn: Callable,
              x_data: Optional[np.ndarray] = None,
              y_data: Optional[np.ndarray] = None,
              x_boundary: Optional[np.ndarray] = None,
              y_boundary: Optional[np.ndarray] = None,
              verbose: int = 100):
        """Train the PINN."""
        print(f"\n{'='*80}")
        print("TRAINING PHYSICS-INFORMED NEURAL NETWORK")
        print(f"{'='*80}\n")
        
        for epoch in range(epochs):
            losses = self.train_step(
                x_physics, physics_loss_fn,
                x_data, y_data,
                x_boundary, y_boundary
            )
            
            # Record history
            self.history['loss'].append(losses['total'])
            self.history['physics_loss'].append(losses['physics'])
            self.history['data_loss'].append(losses['data'])
            self.history['boundary_loss'].append(losses['boundary'])
            
            if epoch % verbose == 0:
                print(f"Epoch {epoch:5d} | "
                      f"Total: {losses['total']:.6f} | "
                      f"Physics: {losses['physics']:.6f} | "
                      f"Data: {losses['data']:.6f} | "
                      f"Boundary: {losses['boundary']:.6f}")
        
        print(f"\nâœ“ Training complete after {epochs} epochs")
        return self.history


class VariablePhysicsPINN:
    """
    PINN that works with variable physical constants from Universe Compiler.
    """
    
    def __init__(self, 
                 universe_compiler: 'UniverseCompiler',
                 physics_module_name: str,
                 equation_name: str):
        self.compiler = universe_compiler
        self.module_name = physics_module_name
        self.equation_name = equation_name
        
        # Get the physics equation
        self.equation = compiler.get_equation(physics_module_name, equation_name)
        
        # Create PINN
        self.pinn = PhysicsInformedNN(
            input_dim=2,  # (x, t) typically
            output_dim=1,
            hidden_layers=[64, 64, 64]
        )
    
    def create_physics_loss(self, parameter_values: Dict[str, float]) -> Callable:
        """
        Create physics loss function with specific parameter values.
        """
        # Substitute parameter values into equation
        eq_substituted = self.equation.subs(parameter_values)
        
        def physics_loss_fn(x, u, grads):
            """
            Compute physics equation residual.
            x: input coordinates
            u: network prediction
            grads: computed gradients
            """
            # This would evaluate the PDE residual
            # Simplified placeholder
            return grads['d00'] - 0.01 * grads['d11']  # Example: heat equation
        
        return physics_loss_fn
    
    def solve_with_parameters(self,
                             parameter_values: Dict[str, float],
                             x_domain: np.ndarray,
                             epochs: int = 1000) -> np.ndarray:
        """
        Solve physics equation with specific parameter values.
        """
        print(f"\n{'='*80}")
        print(f"SOLVING {self.equation_name} FROM {self.module_name}")
        print(f"WITH PARAMETERS: {parameter_values}")
        print(f"{'='*80}")
        
        # Create physics loss for these parameters
        physics_loss = self.create_physics_loss(parameter_values)
        
        # Generate collocation points
        x_physics = self._generate_collocation_points(x_domain, n_points=100)
        
        # Train PINN
        self.pinn.train(
            epochs=epochs,
            x_physics=x_physics,
            physics_loss_fn=physics_loss,
            verbose=epochs // 10
        )
        
        # Return solution on domain
        solution = self.pinn.forward(x_domain)
        return solution
    
    def _generate_collocation_points(self, domain, n_points):
        """Generate random collocation points in domain."""
        return np.random.uniform(
            domain.min(axis=0),
            domain.max(axis=0),
            size=(n_points, domain.shape[1])
        )
    
    def compare_universes(self,
                         param_sets: List[Dict[str, float]],
                         x_domain: np.ndarray,
                         epochs: int = 1000):
        """
        Solve same equation in multiple universes with different constants.
        """
        print(f"\n{'='*80}")
        print(f"COMPARING SOLUTIONS ACROSS {len(param_sets)} UNIVERSES")
        print(f"{'='*80}\n")
        
        solutions = []
        for i, params in enumerate(param_sets):
            print(f"\n[Universe {i+1}/{len(param_sets)}]")
            print(f"Parameters: {params}")
            
            solution = self.solve_with_parameters(params, x_domain, epochs)
            solutions.append({
                'parameters': params,
                'solution': solution
            })
        
        return solutions


def example_heat_equation():
    """
    Example: Heat equation with variable thermal diffusivity.
    
    âˆ‚u/âˆ‚t = Î± âˆ‚Â²u/âˆ‚xÂ²
    
    Where Î± is the thermal diffusivity (variable "constant").
    """
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     HEAT EQUATION PINN EXAMPLE                            â•‘
â•‘                  âˆ‚u/âˆ‚t = Î± âˆ‚Â²u/âˆ‚xÂ² (variable Î±)                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Create PINN
    pinn = PhysicsInformedNN(
        input_dim=2,  # (x, t)
        output_dim=1,  # u(x, t)
        hidden_layers=[32, 32, 32]
    )
    
    # Define heat equation physics loss
    def heat_equation_loss(x, u, grads, alpha=0.01):
        """
        Heat equation residual: âˆ‚u/âˆ‚t - Î± âˆ‚Â²u/âˆ‚xÂ²
        grads['d0'] = âˆ‚u/âˆ‚x
        grads['d1'] = âˆ‚u/âˆ‚t
        grads['d00'] = âˆ‚Â²u/âˆ‚xÂ²
        """
        du_dt = grads['d1']
        d2u_dx2 = grads['d00']
        residual = du_dt - alpha * d2u_dx2
        return residual
    
    # Create domain: x âˆˆ [0, 1], t âˆˆ [0, 1]
    n_points = 100
    x_physics = np.random.rand(n_points, 2)  # Random collocation points
    
    # Boundary conditions: u(0, t) = 0, u(1, t) = 0
    n_boundary = 20
    t_boundary = np.linspace(0, 1, n_boundary).reshape(-1, 1)
    x_boundary_left = np.hstack([np.zeros((n_boundary, 1)), t_boundary])
    x_boundary_right = np.hstack([np.ones((n_boundary, 1)), t_boundary])
    x_boundary = np.vstack([x_boundary_left, x_boundary_right])
    y_boundary = np.zeros((2*n_boundary, 1))
    
    # Initial condition: u(x, 0) = sin(Ï€x)
    n_initial = 20
    x_initial = np.linspace(0, 1, n_initial).reshape(-1, 1)
    t_initial = np.zeros((n_initial, 1))
    x_data = np.hstack([x_initial, t_initial])
    y_data = np.sin(np.pi * x_initial)
    
    print("\nğŸ“Š Problem Setup:")
    print(f"  Domain: x âˆˆ [0, 1], t âˆˆ [0, 1]")
    print(f"  Initial: u(x, 0) = sin(Ï€x)")
    print(f"  Boundary: u(0, t) = u(1, t) = 0")
    print(f"  Physics: âˆ‚u/âˆ‚t = Î± âˆ‚Â²u/âˆ‚xÂ²")
    print(f"  Thermal diffusivity: Î± = 0.01")
    
    # Train
    history = pinn.train(
        epochs=500,
        x_physics=x_physics,
        physics_loss_fn=lambda x, u, g: heat_equation_loss(x, u, g, alpha=0.01),
        x_data=x_data,
        y_data=y_data,
        x_boundary=x_boundary,
        y_boundary=y_boundary,
        verbose=100
    )
    
    # Test solution
    x_test = np.linspace(0, 1, 50).reshape(-1, 1)
    t_test = np.ones((50, 1)) * 0.5  # t = 0.5
    test_points = np.hstack([x_test, t_test])
    u_pred = pinn.forward(test_points)
    
    print(f"\nğŸ“ˆ Solution at t = 0.5:")
    print(f"  x = 0.5: u â‰ˆ {pinn.forward(np.array([[0.5, 0.5]]))[0, 0]:.4f}")
    
    return pinn, history


def example_wave_equation():
    """
    Example: Wave equation with variable wave speed.
    
    âˆ‚Â²u/âˆ‚tÂ² = cÂ² âˆ‚Â²u/âˆ‚xÂ²
    
    Where c is the wave speed (variable).
    """
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     WAVE EQUATION PINN EXAMPLE                            â•‘
â•‘                  âˆ‚Â²u/âˆ‚tÂ² = cÂ² âˆ‚Â²u/âˆ‚xÂ² (variable c)                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    pinn = PhysicsInformedNN(
        input_dim=2,
        output_dim=1,
        hidden_layers=[32, 32, 32]
    )
    
    def wave_equation_loss(x, u, grads, c=1.0):
        """Wave equation residual."""
        d2u_dt2 = grads['d11']
        d2u_dx2 = grads['d00']
        residual = d2u_dt2 - c**2 * d2u_dx2
        return residual
    
    # Domain
    n_points = 100
    x_physics = np.random.rand(n_points, 2)
    
    print("\nğŸ“Š Problem Setup:")
    print(f"  Domain: x âˆˆ [0, 1], t âˆˆ [0, 1]")
    print(f"  Physics: âˆ‚Â²u/âˆ‚tÂ² = cÂ² âˆ‚Â²u/âˆ‚xÂ²")
    print(f"  Wave speed: c = 1.0")
    
    history = pinn.train(
        epochs=500,
        x_physics=x_physics,
        physics_loss_fn=lambda x, u, g: wave_equation_loss(x, u, g, c=1.0),
        verbose=100
    )
    
    return pinn, history


def example_variable_physics():
    """
    Example: Same equation, different physical constants.
    Demonstrates how PINN learns different solutions for different universes.
    """
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              VARIABLE PHYSICS EXAMPLE: DIFFUSION ACROSS UNIVERSES         â•‘
â•‘                     âˆ‚u/âˆ‚t = D âˆ‚Â²u/âˆ‚xÂ² (variable D)                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Test with different diffusion coefficients
    D_values = [0.001, 0.01, 0.1, 1.0]
    
    results = []
    
    for D in D_values:
        print(f"\n{'='*80}")
        print(f"UNIVERSE with D = {D}")
        print(f"{'='*80}")
        
        pinn = PhysicsInformedNN(
            input_dim=2,
            output_dim=1,
            hidden_layers=[32, 32, 32]
        )
        
        def diffusion_loss(x, u, grads):
            du_dt = grads['d1']
            d2u_dx2 = grads['d00']
            return du_dt - D * d2u_dx2
        
        x_physics = np.random.rand(100, 2)
        
        history = pinn.train(
            epochs=200,
            x_physics=x_physics,
            physics_loss_fn=diffusion_loss,
            verbose=50
        )
        
        # Test at t=0.5, x=0.5
        test_point = np.array([[0.5, 0.5]])
        solution = pinn.forward(test_point)[0, 0]
        
        results.append({
            'D': D,
            'solution': solution,
            'final_loss': history['loss'][-1]
        })
        
        print(f"\n  Solution at (0.5, 0.5): {solution:.6f}")
        print(f"  Final loss: {history['loss'][-1]:.6f}")
    
    print(f"\n{'='*80}")
    print("COMPARISON ACROSS UNIVERSES")
    print(f"{'='*80}\n")
    
    print("  D       | u(0.5, 0.5) | Final Loss")
    print("  " + "-"*44)
    for r in results:
        print(f"  {r['D']:.3f}   | {r['solution']:11.6f} | {r['final_loss']:.6f}")
    
    print(f"\n  Higher D â†’ Faster diffusion â†’ Different solutions")
    print(f"  Same PDE, different constants = different realities")
    
    return results


def demonstrate_pinn_system():
    """Run all demonstrations."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              L104 PHYSICS-INFORMED NEURAL NETWORKS v1.0                   â•‘
â•‘         Neural Networks That Learn While Respecting Physics Laws          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CAPABILITIES:
  â€¢ Solve PDEs using neural networks
  â€¢ Enforce physics constraints through loss function
  â€¢ Handle variable physical constants
  â€¢ Compare solutions across different universes
  â€¢ Automatic differentiation for gradients

DEMONSTRATIONS:
  1. Heat equation (thermal diffusion)
  2. Wave equation (wave propagation)
  3. Variable physics (same PDE, different constants)
    """)
    
    input("\nPress Enter to begin demonstrations...")
    
    # Demo 1: Heat equation
    pinn_heat, history_heat = example_heat_equation()
    input("\nPress Enter for next demo...")
    
    # Demo 2: Wave equation
    pinn_wave, history_wave = example_wave_equation()
    input("\nPress Enter for next demo...")
    
    # Demo 3: Variable physics
    results_variable = example_variable_physics()
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                     DEMONSTRATIONS COMPLETE                               â•‘
â•‘                                                                           â•‘
â•‘  Physics-Informed Neural Networks successfully demonstrated:             â•‘
â•‘    â€¢ Learning solutions to PDEs                                          â•‘
â•‘    â€¢ Respecting physics constraints                                      â•‘
â•‘    â€¢ Handling variable constants                                         â•‘
â•‘    â€¢ Comparing across universes                                          â•‘
â•‘                                                                           â•‘
â•‘  Neural networks that understand physics.                                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    return {
        'heat': (pinn_heat, history_heat),
        'wave': (pinn_wave, history_wave),
        'variable': results_variable
    }


if __name__ == "__main__":
    # Check if Universe Compiler is available
    if UNIVERSE_AVAILABLE:
        print("âœ“ Universe Compiler integration available")
        print("  PINNs can use variable physical constants\n")
    else:
        print("âš ï¸ Running in standalone mode")
        print("  Install l104_universe_compiler.py for full features\n")
    
    # Run demonstrations
    results = demonstrate_pinn_system()
