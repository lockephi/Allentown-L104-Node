\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\title{L104 Neuro-Symbolic Integration: Mathematical Derivations}
\author{LONDEL}
\date{\today}
\begin{document}
\maketitle
\section{Introduction}
This document contains formal mathematical derivations for the L104 neuro-symbolic integration system.

\section{Neuro-Symbolic Integration Theorem}

\textbf{Loss Function:}

$\mathcal{L}(t) = (N(t) - S(t))^2 = \left(N{\left(t \right)} - S{\left(t \right)}\right)^{2}$

\textbf{Integrated Loss:}

$\mathcal{I} = \int_{0}^{T} \left(N{\left(t \right)} - S{\left(t \right)}\right)^{2} \, dt = \int\limits_{0}^{T} \left(N{\left(t \right)} - S{\left(t \right)}\right)^{2}\, dt$

\textbf{Gradient:}

$\frac{d\mathcal{L}}{dt} = \left(N{\left(t \right)} - S{\left(t \right)}\right) \left(2 \frac{d}{d t} N{\left(t \right)} - 2 \frac{d}{d t} S{\left(t \right)}\right)$

\textit{Verification status: verified}

\section{Modus Ponens (Neural-Symbolic)}

\textbf{Classical Modus Ponens:}

$\frac{P \implies Q, \quad P}{Q}$

\textbf{Premise 1:}

$P \Rightarrow Q$

\textbf{Premise 2:}

$P$

\textbf{Conclusion:}

$Q$

\textbf{Neural Weight:}

$w = w_{1} w_{2}$

\textbf{Weighted Conclusion:}

$w_{1} w_{2} \cdot Q$

\textit{Verification status: verified}

\section{Sigmoid Activation Gradient}

\textbf{Sigmoid Function:}

$\sigma(x) = \frac{1}{1 + e^{- x}}$

\textbf{Derivative:}

$\frac{d\sigma}{dx} = \frac{e^{- x}}{\left(1 + e^{- x}\right)^{2}}$

\textbf{Simplified:}

$\sigma'(x) = \frac{1}{4 \cosh^{2}{\left(\frac{x}{2} \right)}}$

\textbf{Standard Form:}

$\sigma'(x) = \sigma(x)(1 - \sigma(x))$

\textbf{Verification:}

$\frac{1}{4 \cosh^{2}{\left(\frac{x}{2} \right)}} = \frac{1 - \frac{1}{1 + e^{- x}}}{1 + e^{- x}}$

\textit{Verification status: verified}

\section{Symbolic-to-Neural Projection}

\textbf{Embedding Vectors:}

$p, q \in \mathbb{R}^{128}$

\textbf{Cosine Similarity:}

$\cos(\theta_{pq}) = \cos{\left(theta_{pq} \right)}$

\textbf{Inner Product:}

$\langle p, q \rangle = ||p|| ||q|| \cos{\left(theta_{pq} \right)}$

\textbf{Normalized:}

$\frac{\langle p, q \rangle}{||p|| \cdot ||q||} = \cos{\left(theta_{pq} \right)}$

\textit{Verification status: verified}

\section{Knowledge Graph Diffusion}

\textbf{Diffusion Equation:}

$\frac{\partial}{\partial t} u{\left(x,t \right)} = D \frac{\partial^{2}}{\partial x^{2}} u{\left(x,t \right)}$

\textbf{Laplacian:}

$\nabla^2 u = \frac{\partial^{2}}{\partial x^{2}} u{\left(x,t \right)}$

\textbf{Gaussian Solution:}

$u(x,t) = \frac{e^{- \frac{x^{2}}{4 D t}}}{2 \sqrt{\pi} \sqrt{D} \sqrt{t}}$

\textbf{Graph Laplacian:}

$\mathbf{L} = \mathbf{D} - \mathbf{A}$

\textbf{Discrete Update:}

$\frac{du}{dt} = -\mathbf{L}u$

\textit{Verification status: verified}

\section{Attention Mechanism}

\textbf{Attention Score:}

$s = \frac{qk}{\sqrt{d_k}} = \frac{k q}{\sqrt{d_{k}}}$

\textbf{Exponential:}

$e^s = e^{\frac{k q}{\sqrt{d_{k}}}}$

\textbf{Gradient w.r.t. Q:}

$\frac{\partial s}{\partial q} = \frac{k}{\sqrt{d_{k}}}$

\textbf{Softmax:}

$\text{softmax}(s) = \frac{e^s}{\sum e^s}$

\textbf{Full Attention:}

$\text{Attention}(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V$

\textit{Verification status: verified}

\section{Logical Consistency Constraint}

\textbf{Contradiction:}

$P \wedge \neg P$

\textbf{Unsatisfiability:}

$\text{SAT}(P \wedge \neg P) = \text{False}$

\textbf{Probability Sum:}

$P(p) + P(\neg p) = 1$

\textbf{Consistency:}

$P(p \land \neg p) = 0$

\textbf{Neural Constraint:}

$P_{notp} + P_{p} - 1 = 0$

\textit{Verification status: verified}

\end{document}